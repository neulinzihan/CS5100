{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2899e092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from gymnasium import Env, spaces\n",
    "import torch\n",
    "\n",
    "# Constants\n",
    "UNEXPLORED = -2\n",
    "OBSTACLE = -1\n",
    "SAFE = 0\n",
    "\n",
    "# === Utility Functions ===\n",
    "def drone_scan(drone_pos, scan_range, actual_env):\n",
    "    half_range = scan_range // 2\n",
    "    local_info = np.full((scan_range, scan_range), UNEXPLORED)\n",
    "    grid_h, grid_w = actual_env.shape\n",
    "\n",
    "    for i in range(scan_range):\n",
    "        for j in range(scan_range):\n",
    "            global_x = drone_pos[0] - half_range + i\n",
    "            global_y = drone_pos[1] - half_range + j\n",
    "            if 0 <= global_x < grid_h and 0 <= global_y < grid_w:\n",
    "                local_info[i, j] = actual_env[global_x, global_y]\n",
    "\n",
    "    return local_info, (drone_pos[0] - half_range, drone_pos[1] - half_range)\n",
    "\n",
    "def stitch_information(global_grid, local_info, top_left):\n",
    "    x_offset, y_offset = top_left\n",
    "    grid_h, grid_w = global_grid.shape\n",
    "\n",
    "    for i in range(local_info.shape[0]):\n",
    "        for j in range(local_info.shape[1]):\n",
    "            x, y = x_offset + i, y_offset + j\n",
    "            if 0 <= x < grid_h and 0 <= y < grid_w:\n",
    "                if global_grid[x, y] == UNEXPLORED:\n",
    "                    global_grid[x, y] = local_info[i, j]\n",
    "                elif global_grid[x, y] != local_info[i, j]:\n",
    "                    if local_info[i, j] == SAFE:\n",
    "                        global_grid[x, y] = SAFE\n",
    "    return global_grid\n",
    "\n",
    "# === Custom Environment ===\n",
    "class DronePlacementEnv(Env):\n",
    "    def __init__(self, grid_size=10, max_steps=50):\n",
    "        super().__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.max_steps = max_steps\n",
    "        self.current_step = 0\n",
    "\n",
    "        self.action_space = spaces.Discrete(grid_size * grid_size * 2)\n",
    "        self.observation_space = spaces.Box(low=UNEXPLORED, high=SAFE, shape=(grid_size, grid_size), dtype=np.int32)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.actual_env = np.random.choice([OBSTACLE, SAFE], size=(self.grid_size, self.grid_size), p=[0.2, 0.8]).astype(np.int32)\n",
    "        self.global_grid = np.full((self.grid_size, self.grid_size), UNEXPLORED, dtype=np.int32)\n",
    "        self.current_step = 0\n",
    "        return self.global_grid.copy(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "        action = int(min(action, self.grid_size * self.grid_size * 2 - 1))\n",
    "        action_per_row = self.grid_size * 2\n",
    "        x = action // action_per_row\n",
    "        y = (action % action_per_row) // 2\n",
    "        drone_type = action % 2\n",
    "\n",
    "        if not (0 <= x < self.grid_size and 0 <= y < self.grid_size):\n",
    "            raise ValueError(f\"Decoded position ({x}, {y}) is out of bounds!\")\n",
    "\n",
    "        scan_range = 3 if drone_type == 0 else 5\n",
    "        local_info, top_left = drone_scan((x, y), scan_range, self.actual_env)\n",
    "        prev_unexplored = np.sum(self.global_grid == UNEXPLORED)\n",
    "        self.global_grid = stitch_information(self.global_grid, local_info, top_left)\n",
    "        new_unexplored = np.sum(self.global_grid == UNEXPLORED)\n",
    "\n",
    "        reward = float(prev_unexplored - new_unexplored - 0.2 - 0.2 * drone_type)\n",
    "        if x <= 1 or x >= self.grid_size - 2 or y <= 1 or y >= self.grid_size - 2:\n",
    "            reward += 0.3\n",
    "\n",
    "        terminated = bool(new_unexplored == 0)\n",
    "        truncated = bool(self.current_step >= self.max_steps)\n",
    "        if terminated:\n",
    "            reward += 10\n",
    "        elif truncated:\n",
    "            reward -= 5\n",
    "\n",
    "        return self.global_grid.copy(), reward, terminated, truncated, {}\n",
    "\n",
    "    def render(self):\n",
    "        print(self.global_grid)\n",
    "\n",
    "# === Small Map Env ===\n",
    "class SmallDroneEnv(DronePlacementEnv):\n",
    "    def __init__(self):\n",
    "        super().__init__(grid_size=6, max_steps=8)\n",
    "\n",
    "# === Training Functions ===\n",
    "def save_small_model_encoder():\n",
    "    env = SmallDroneEnv()\n",
    "    model = PPO(\"MlpPolicy\", env, verbose=0)\n",
    "    model.learn(total_timesteps=20000)\n",
    "    torch.save(model.policy.mlp_extractor.state_dict(), \"small_encoder.pt\")\n",
    "    model.save(\"ppo_small_model\")\n",
    "    return model\n",
    "\n",
    "def train_large_model_with_transfer():\n",
    "    env = DronePlacementEnv()\n",
    "    # policy net arch ç»“æ„éœ€è¦å…¼å®¹ï¼ˆæˆ–æ›´å¤§ï¼‰\n",
    "    policy_kwargs = dict(net_arch=[dict(pi=[64, 64], vf=[64, 64])])\n",
    "    model = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=1)\n",
    "    # åŠ è½½å°æ¨¡å‹ encoder çš„æƒé‡\n",
    "    encoder_weights = torch.load(\"small_encoder.pt\")\n",
    "    model.policy.mlp_extractor.load_state_dict(encoder_weights, strict=False)  # åªåŒ¹é…ç»“æ„å…¼å®¹çš„éƒ¨åˆ†\n",
    "    model.learn(total_timesteps=100000)\n",
    "    model.save(\"ppo_large_model\")\n",
    "\n",
    "\n",
    "def run_trained_model():\n",
    "    model = PPO.load(\"ppo_large_model\")\n",
    "    env = DronePlacementEnv()\n",
    "    obs, _ = env.reset()\n",
    "\n",
    "    for step in range(env.max_steps):\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        x = action // 20\n",
    "        y = (action % 20) // 2\n",
    "        drone_type = \"3x3\" if action % 2 == 0 else \"5x5\"\n",
    "        print(f\"Step {step}: Placed {drone_type} drone at ({x}, {y}), reward: {reward:.2f}\")\n",
    "        env.render()\n",
    "        if terminated or truncated:\n",
    "            print(\"ğŸ‰ Mission Complete: All cells explored!\")\n",
    "            break\n",
    "        if truncated:\n",
    "            print(\"âš ï¸ Max steps reached.\")\n",
    "            break\n",
    "\n",
    "# === Entry Point ===\n",
    "if __name__ == \"__main__\":\n",
    "    save_small_model_encoder()           # å…ˆè®­ç»ƒå¹¶ä¿å­˜å°åœ°å›¾ encoder\n",
    "    train_large_model_with_transfer()    # è¿ç§» encoder åˆ°å¤§åœ°å›¾ç»§ç»­è®­ç»ƒ\n",
    "    run_trained_model()      \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchsafe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
