{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jacY87pDLOxO"
      },
      "source": [
        "4 models each one with different env settings. \\\n",
        "Every model trained with Curriculum Learning: 6x6+8x8 or 6x6+8x8+10x10. \\\n",
        "Then a matrix sequence is shown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4rc-LyMJAZn"
      },
      "source": [
        "# Env 1: Basic, DronePlacementEnv, Static grid. Resultâ‰ˆ8steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "7ZHFxkSbWkNM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from gymnasium import Env, spaces\n",
        "import torch\n",
        "\n",
        "UNEXPLORED = -1\n",
        "OBSTACLE = 0\n",
        "SAFE = 1\n",
        "\n",
        "def drone_scan(drone_pos, scan_range, actual_env):\n",
        "    half_range = scan_range // 2\n",
        "    local_info = np.full((scan_range, scan_range), UNEXPLORED)\n",
        "    grid_h, grid_w = actual_env.shape\n",
        "\n",
        "    for i in range(scan_range):\n",
        "        for j in range(scan_range):\n",
        "            global_x = drone_pos[0] - half_range + i\n",
        "            global_y = drone_pos[1] - half_range + j\n",
        "            if 0 <= global_x < grid_h and 0 <= global_y < grid_w:\n",
        "                local_info[i, j] = actual_env[global_x, global_y]\n",
        "\n",
        "    return local_info, (drone_pos[0] - half_range, drone_pos[1] - half_range)\n",
        "\n",
        "def stitch_information(global_grid, local_info, top_left):\n",
        "    x_offset, y_offset = top_left\n",
        "    grid_h, grid_w = global_grid.shape\n",
        "\n",
        "    for i in range(local_info.shape[0]):\n",
        "        for j in range(local_info.shape[1]):\n",
        "            x, y = x_offset + i, y_offset + j\n",
        "            if 0 <= x < grid_h and 0 <= y < grid_w:\n",
        "                if global_grid[x, y] == UNEXPLORED:\n",
        "                    global_grid[x, y] = local_info[i, j]\n",
        "                elif global_grid[x, y] != local_info[i, j]:\n",
        "                    if local_info[i, j] == SAFE:\n",
        "                        global_grid[x, y] = SAFE\n",
        "    return global_grid\n",
        "\n",
        "class DronePlacementEnv(Env):\n",
        "    def __init__(self, grid_size=10, max_steps=50):\n",
        "        super().__init__()\n",
        "        self.grid_size = grid_size\n",
        "        self.max_steps = max_steps\n",
        "        self.current_step = 0\n",
        "\n",
        "        self.action_space = spaces.Discrete(grid_size * grid_size * 2)\n",
        "        self.observation_space = spaces.Box(low=UNEXPLORED, high=SAFE, shape=(grid_size, grid_size), dtype=np.int32)\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.actual_env = np.random.choice([OBSTACLE, SAFE], size=(self.grid_size, self.grid_size), p=[0.2, 0.8]).astype(np.int32)\n",
        "        self.global_grid = np.full((self.grid_size, self.grid_size), UNEXPLORED, dtype=np.int32)\n",
        "        self.current_step = 0\n",
        "        return self.global_grid.copy(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_step += 1\n",
        "        action = int(min(action, self.grid_size * self.grid_size * 2 - 1))\n",
        "        action_per_row = self.grid_size * 2\n",
        "        x = action // action_per_row\n",
        "        y = (action % action_per_row) // 2\n",
        "        drone_type = action % 2\n",
        "\n",
        "        if not (0 <= x < self.grid_size and 0 <= y < self.grid_size):\n",
        "            raise ValueError(f\"Decoded position ({x}, {y}) is out of bounds!\")\n",
        "\n",
        "        scan_range = 3 if drone_type == 0 else 5\n",
        "        local_info, top_left = drone_scan((x, y), scan_range, self.actual_env)\n",
        "        prev_unexplored = np.sum(self.global_grid == UNEXPLORED)\n",
        "        self.global_grid = stitch_information(self.global_grid, local_info, top_left)\n",
        "        new_unexplored = np.sum(self.global_grid == UNEXPLORED)\n",
        "\n",
        "        reward = float(prev_unexplored - new_unexplored - 0.2 - 0.2 * drone_type)\n",
        "        if x <= 1 or x >= self.grid_size - 2 or y <= 1 or y >= self.grid_size - 2:\n",
        "            reward += 0.3\n",
        "\n",
        "        terminated = bool(new_unexplored == 0)\n",
        "        truncated = bool(self.current_step >= self.max_steps)\n",
        "        if terminated:\n",
        "            reward += 10\n",
        "        elif truncated:\n",
        "            reward -= 5\n",
        "\n",
        "        return self.global_grid.copy(), reward, terminated, truncated, {}\n",
        "\n",
        "    def render(self):\n",
        "        print(self.global_grid)\n",
        "\n",
        "class SmallDroneEnv(DronePlacementEnv):\n",
        "    def __init__(self):\n",
        "        super().__init__(grid_size=6, max_steps=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkHw3v0GEsB0",
        "outputId": "c16b3a09-54c7-4e09-d740-72b078400623"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 34.9     |\n",
            "|    ep_rew_mean     | 105      |\n",
            "| time/              |          |\n",
            "|    fps             | 702      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 2        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 36.9        |\n",
            "|    ep_rew_mean          | 103         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 568         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 7           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022465367 |\n",
            "|    clip_fraction        | 0.205       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.28       |\n",
            "|    explained_variance   | 0.022       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 168         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0709     |\n",
            "|    value_loss           | 558         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 36.6        |\n",
            "|    ep_rew_mean          | 102         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 505         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 12          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016948618 |\n",
            "|    clip_fraction        | 0.156       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.23       |\n",
            "|    explained_variance   | 0.158       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 142         |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0627     |\n",
            "|    value_loss           | 367         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 34.5        |\n",
            "|    ep_rew_mean          | 103         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 496         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 16          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017508699 |\n",
            "|    clip_fraction        | 0.158       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.23       |\n",
            "|    explained_variance   | 0.364       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 115         |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.061      |\n",
            "|    value_loss           | 314         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 36.1        |\n",
            "|    ep_rew_mean          | 103         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 492         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 20          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018090855 |\n",
            "|    clip_fraction        | 0.148       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.22       |\n",
            "|    explained_variance   | 0.47        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 115         |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0597     |\n",
            "|    value_loss           | 277         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 38.2        |\n",
            "|    ep_rew_mean          | 101         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 456         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 26          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023424465 |\n",
            "|    clip_fraction        | 0.225       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.19       |\n",
            "|    explained_variance   | 0.566       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 36.5        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0703     |\n",
            "|    value_loss           | 192         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 37.7        |\n",
            "|    ep_rew_mean          | 103         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 459         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 31          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022762425 |\n",
            "|    clip_fraction        | 0.231       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.16       |\n",
            "|    explained_variance   | 0.651       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 29.9        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0683     |\n",
            "|    value_loss           | 160         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 36          |\n",
            "|    ep_rew_mean          | 103         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 461         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 35          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020614317 |\n",
            "|    clip_fraction        | 0.242       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.13       |\n",
            "|    explained_variance   | 0.737       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 46.4        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.066      |\n",
            "|    value_loss           | 121         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 35.2        |\n",
            "|    ep_rew_mean          | 104         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 454         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 40          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019882215 |\n",
            "|    clip_fraction        | 0.216       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.15       |\n",
            "|    explained_variance   | 0.799       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 20.2        |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0662     |\n",
            "|    value_loss           | 91.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 35.1        |\n",
            "|    ep_rew_mean          | 104         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 457         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 44          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021937372 |\n",
            "|    clip_fraction        | 0.226       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.11       |\n",
            "|    explained_variance   | 0.855       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 23.6        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0641     |\n",
            "|    value_loss           | 66          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 36.1        |\n",
            "|    ep_rew_mean          | 104         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 459         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 49          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022340905 |\n",
            "|    clip_fraction        | 0.238       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.09       |\n",
            "|    explained_variance   | 0.889       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 22.7        |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0645     |\n",
            "|    value_loss           | 46.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 34.4        |\n",
            "|    ep_rew_mean          | 105         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 454         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 54          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022780363 |\n",
            "|    clip_fraction        | 0.243       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.08       |\n",
            "|    explained_variance   | 0.918       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 16.7        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0651     |\n",
            "|    value_loss           | 35.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 33.3        |\n",
            "|    ep_rew_mean          | 105         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 456         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 58          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021469545 |\n",
            "|    clip_fraction        | 0.257       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.09       |\n",
            "|    explained_variance   | 0.936       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.83        |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0684     |\n",
            "|    value_loss           | 26.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 33.4        |\n",
            "|    ep_rew_mean          | 105         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 457         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 62          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022976583 |\n",
            "|    clip_fraction        | 0.268       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.06       |\n",
            "|    explained_variance   | 0.958       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.09        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.069      |\n",
            "|    value_loss           | 16.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 32.1        |\n",
            "|    ep_rew_mean          | 105         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 453         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 67          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022242835 |\n",
            "|    clip_fraction        | 0.247       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.06       |\n",
            "|    explained_variance   | 0.97        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.86        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0691     |\n",
            "|    value_loss           | 11.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 31.6        |\n",
            "|    ep_rew_mean          | 105         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 455         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 72          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022170838 |\n",
            "|    clip_fraction        | 0.26        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.03       |\n",
            "|    explained_variance   | 0.975       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.7         |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0736     |\n",
            "|    value_loss           | 8.18        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 31.2        |\n",
            "|    ep_rew_mean          | 106         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 455         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 76          |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022322059 |\n",
            "|    clip_fraction        | 0.25        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.02       |\n",
            "|    explained_variance   | 0.98        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.61        |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0756     |\n",
            "|    value_loss           | 6.07        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 31.6        |\n",
            "|    ep_rew_mean          | 106         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 453         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 81          |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022593303 |\n",
            "|    clip_fraction        | 0.254       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5          |\n",
            "|    explained_variance   | 0.986       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.15        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0791     |\n",
            "|    value_loss           | 4.11        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30.9        |\n",
            "|    ep_rew_mean          | 106         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 454         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 85          |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023229212 |\n",
            "|    clip_fraction        | 0.27        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.01       |\n",
            "|    explained_variance   | 0.988       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.913       |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.0833     |\n",
            "|    value_loss           | 3.28        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 32.5        |\n",
            "|    ep_rew_mean          | 105         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 455         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 90          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021758294 |\n",
            "|    clip_fraction        | 0.263       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.98       |\n",
            "|    explained_variance   | 0.989       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.486       |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0847     |\n",
            "|    value_loss           | 2.91        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30.1        |\n",
            "|    ep_rew_mean          | 106         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 453         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 94          |\n",
            "|    total_timesteps      | 43008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022697035 |\n",
            "|    clip_fraction        | 0.264       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.96       |\n",
            "|    explained_variance   | 0.988       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.325       |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.084      |\n",
            "|    value_loss           | 2.86        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 30.6       |\n",
            "|    ep_rew_mean          | 106        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 454        |\n",
            "|    iterations           | 22         |\n",
            "|    time_elapsed         | 99         |\n",
            "|    total_timesteps      | 45056      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02305206 |\n",
            "|    clip_fraction        | 0.275      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.98      |\n",
            "|    explained_variance   | 0.99       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.6        |\n",
            "|    n_updates            | 210        |\n",
            "|    policy_gradient_loss | -0.086     |\n",
            "|    value_loss           | 2.36       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 30.6      |\n",
            "|    ep_rew_mean          | 106       |\n",
            "| time/                   |           |\n",
            "|    fps                  | 451       |\n",
            "|    iterations           | 23        |\n",
            "|    time_elapsed         | 104       |\n",
            "|    total_timesteps      | 47104     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0244582 |\n",
            "|    clip_fraction        | 0.304     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -4.94     |\n",
            "|    explained_variance   | 0.991     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.575     |\n",
            "|    n_updates            | 220       |\n",
            "|    policy_gradient_loss | -0.09     |\n",
            "|    value_loss           | 1.93      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 29.6        |\n",
            "|    ep_rew_mean          | 106         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 451         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 108         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021889506 |\n",
            "|    clip_fraction        | 0.252       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.91       |\n",
            "|    explained_variance   | 0.99        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.271       |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0833     |\n",
            "|    value_loss           | 2.3         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 28.8        |\n",
            "|    ep_rew_mean          | 107         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 452         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 113         |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022499492 |\n",
            "|    clip_fraction        | 0.271       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.89       |\n",
            "|    explained_variance   | 0.991       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.254       |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0846     |\n",
            "|    value_loss           | 2.14        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 29.6       |\n",
            "|    ep_rew_mean          | 107        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 450        |\n",
            "|    iterations           | 26         |\n",
            "|    time_elapsed         | 118        |\n",
            "|    total_timesteps      | 53248      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02306896 |\n",
            "|    clip_fraction        | 0.288      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.88      |\n",
            "|    explained_variance   | 0.992      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.172      |\n",
            "|    n_updates            | 250        |\n",
            "|    policy_gradient_loss | -0.0863    |\n",
            "|    value_loss           | 1.8        |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30.3        |\n",
            "|    ep_rew_mean          | 106         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 451         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 122         |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024128173 |\n",
            "|    clip_fraction        | 0.281       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.89       |\n",
            "|    explained_variance   | 0.992       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.509       |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.086      |\n",
            "|    value_loss           | 1.73        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 27.2       |\n",
            "|    ep_rew_mean          | 107        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 452        |\n",
            "|    iterations           | 28         |\n",
            "|    time_elapsed         | 126        |\n",
            "|    total_timesteps      | 57344      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02477049 |\n",
            "|    clip_fraction        | 0.301      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.87      |\n",
            "|    explained_variance   | 0.992      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.229      |\n",
            "|    n_updates            | 270        |\n",
            "|    policy_gradient_loss | -0.0881    |\n",
            "|    value_loss           | 1.8        |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 28.4       |\n",
            "|    ep_rew_mean          | 108        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 450        |\n",
            "|    iterations           | 29         |\n",
            "|    time_elapsed         | 131        |\n",
            "|    total_timesteps      | 59392      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02633122 |\n",
            "|    clip_fraction        | 0.316      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.84      |\n",
            "|    explained_variance   | 0.993      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.157      |\n",
            "|    n_updates            | 280        |\n",
            "|    policy_gradient_loss | -0.0919    |\n",
            "|    value_loss           | 1.5        |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 26.1        |\n",
            "|    ep_rew_mean          | 108         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 451         |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 136         |\n",
            "|    total_timesteps      | 61440       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023613103 |\n",
            "|    clip_fraction        | 0.288       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.81       |\n",
            "|    explained_variance   | 0.994       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.156       |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.0883     |\n",
            "|    value_loss           | 1.5         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 27.2        |\n",
            "|    ep_rew_mean          | 107         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 452         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 140         |\n",
            "|    total_timesteps      | 63488       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023895849 |\n",
            "|    clip_fraction        | 0.308       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.8        |\n",
            "|    explained_variance   | 0.995       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.198       |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | -0.0875     |\n",
            "|    value_loss           | 1.46        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 26.4        |\n",
            "|    ep_rew_mean          | 107         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 450         |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 145         |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023612984 |\n",
            "|    clip_fraction        | 0.299       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.77       |\n",
            "|    explained_variance   | 0.993       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.307       |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.0892     |\n",
            "|    value_loss           | 1.6         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 26.1        |\n",
            "|    ep_rew_mean          | 107         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 451         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 149         |\n",
            "|    total_timesteps      | 67584       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023569893 |\n",
            "|    clip_fraction        | 0.276       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.76       |\n",
            "|    explained_variance   | 0.994       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.411       |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -0.0838     |\n",
            "|    value_loss           | 1.67        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 25.2        |\n",
            "|    ep_rew_mean          | 108         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 452         |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 154         |\n",
            "|    total_timesteps      | 69632       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024082882 |\n",
            "|    clip_fraction        | 0.278       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.73       |\n",
            "|    explained_variance   | 0.994       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.222       |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | -0.0853     |\n",
            "|    value_loss           | 1.46        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 25.5        |\n",
            "|    ep_rew_mean          | 107         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 450         |\n",
            "|    iterations           | 35          |\n",
            "|    time_elapsed         | 159         |\n",
            "|    total_timesteps      | 71680       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024470698 |\n",
            "|    clip_fraction        | 0.3         |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.68       |\n",
            "|    explained_variance   | 0.995       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.435       |\n",
            "|    n_updates            | 340         |\n",
            "|    policy_gradient_loss | -0.0885     |\n",
            "|    value_loss           | 1.33        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 25.3        |\n",
            "|    ep_rew_mean          | 108         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 451         |\n",
            "|    iterations           | 36          |\n",
            "|    time_elapsed         | 163         |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023049157 |\n",
            "|    clip_fraction        | 0.28        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.66       |\n",
            "|    explained_variance   | 0.993       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.313       |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | -0.0843     |\n",
            "|    value_loss           | 1.73        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 24.6       |\n",
            "|    ep_rew_mean          | 108        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 451        |\n",
            "|    iterations           | 37         |\n",
            "|    time_elapsed         | 167        |\n",
            "|    total_timesteps      | 75776      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02471793 |\n",
            "|    clip_fraction        | 0.304      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.64      |\n",
            "|    explained_variance   | 0.994      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.422      |\n",
            "|    n_updates            | 360        |\n",
            "|    policy_gradient_loss | -0.0886    |\n",
            "|    value_loss           | 1.39       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 25.4        |\n",
            "|    ep_rew_mean          | 108         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 450         |\n",
            "|    iterations           | 38          |\n",
            "|    time_elapsed         | 172         |\n",
            "|    total_timesteps      | 77824       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026990183 |\n",
            "|    clip_fraction        | 0.309       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.6        |\n",
            "|    explained_variance   | 0.995       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.307       |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | -0.0884     |\n",
            "|    value_loss           | 1.3         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 25          |\n",
            "|    ep_rew_mean          | 108         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 451         |\n",
            "|    iterations           | 39          |\n",
            "|    time_elapsed         | 176         |\n",
            "|    total_timesteps      | 79872       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026280873 |\n",
            "|    clip_fraction        | 0.308       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.6        |\n",
            "|    explained_variance   | 0.995       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.169       |\n",
            "|    n_updates            | 380         |\n",
            "|    policy_gradient_loss | -0.0886     |\n",
            "|    value_loss           | 1.21        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 24.4        |\n",
            "|    ep_rew_mean          | 108         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 451         |\n",
            "|    iterations           | 40          |\n",
            "|    time_elapsed         | 181         |\n",
            "|    total_timesteps      | 81920       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025573194 |\n",
            "|    clip_fraction        | 0.303       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.5        |\n",
            "|    explained_variance   | 0.995       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.262       |\n",
            "|    n_updates            | 390         |\n",
            "|    policy_gradient_loss | -0.0858     |\n",
            "|    value_loss           | 1.24        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 23.9        |\n",
            "|    ep_rew_mean          | 108         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 450         |\n",
            "|    iterations           | 41          |\n",
            "|    time_elapsed         | 186         |\n",
            "|    total_timesteps      | 83968       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026653137 |\n",
            "|    clip_fraction        | 0.327       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.43       |\n",
            "|    explained_variance   | 0.996       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.174       |\n",
            "|    n_updates            | 400         |\n",
            "|    policy_gradient_loss | -0.0906     |\n",
            "|    value_loss           | 1.12        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 23.4        |\n",
            "|    ep_rew_mean          | 108         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 451         |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 190         |\n",
            "|    total_timesteps      | 86016       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024757367 |\n",
            "|    clip_fraction        | 0.294       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.37       |\n",
            "|    explained_variance   | 0.995       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.112       |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.0839     |\n",
            "|    value_loss           | 1.21        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 22          |\n",
            "|    ep_rew_mean          | 108         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 450         |\n",
            "|    iterations           | 43          |\n",
            "|    time_elapsed         | 195         |\n",
            "|    total_timesteps      | 88064       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023932725 |\n",
            "|    clip_fraction        | 0.295       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.28       |\n",
            "|    explained_variance   | 0.996       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.169       |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | -0.0808     |\n",
            "|    value_loss           | 1.02        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 20.1        |\n",
            "|    ep_rew_mean          | 109         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 450         |\n",
            "|    iterations           | 44          |\n",
            "|    time_elapsed         | 199         |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024659824 |\n",
            "|    clip_fraction        | 0.285       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.22       |\n",
            "|    explained_variance   | 0.996       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.19        |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.0805     |\n",
            "|    value_loss           | 1.2         |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 22.4       |\n",
            "|    ep_rew_mean          | 108        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 451        |\n",
            "|    iterations           | 45         |\n",
            "|    time_elapsed         | 204        |\n",
            "|    total_timesteps      | 92160      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02378343 |\n",
            "|    clip_fraction        | 0.278      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.1       |\n",
            "|    explained_variance   | 0.996      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.273      |\n",
            "|    n_updates            | 440        |\n",
            "|    policy_gradient_loss | -0.0787    |\n",
            "|    value_loss           | 1.12       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 19.9        |\n",
            "|    ep_rew_mean          | 108         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 450         |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 209         |\n",
            "|    total_timesteps      | 94208       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023730777 |\n",
            "|    clip_fraction        | 0.275       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.15       |\n",
            "|    explained_variance   | 0.996       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.302       |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | -0.0774     |\n",
            "|    value_loss           | 1.07        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 21.3       |\n",
            "|    ep_rew_mean          | 109        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 450        |\n",
            "|    iterations           | 47         |\n",
            "|    time_elapsed         | 213        |\n",
            "|    total_timesteps      | 96256      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02374187 |\n",
            "|    clip_fraction        | 0.276      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.04      |\n",
            "|    explained_variance   | 0.997      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.187      |\n",
            "|    n_updates            | 460        |\n",
            "|    policy_gradient_loss | -0.0781    |\n",
            "|    value_loss           | 1.01       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 19.7        |\n",
            "|    ep_rew_mean          | 108         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 450         |\n",
            "|    iterations           | 48          |\n",
            "|    time_elapsed         | 218         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026015949 |\n",
            "|    clip_fraction        | 0.298       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.05       |\n",
            "|    explained_variance   | 0.997       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0691      |\n",
            "|    n_updates            | 470         |\n",
            "|    policy_gradient_loss | -0.0808     |\n",
            "|    value_loss           | 0.803       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 18.4       |\n",
            "|    ep_rew_mean          | 108        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 449        |\n",
            "|    iterations           | 49         |\n",
            "|    time_elapsed         | 223        |\n",
            "|    total_timesteps      | 100352     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02182547 |\n",
            "|    clip_fraction        | 0.275      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.85      |\n",
            "|    explained_variance   | 0.997      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.561      |\n",
            "|    n_updates            | 480        |\n",
            "|    policy_gradient_loss | -0.0715    |\n",
            "|    value_loss           | 1.06       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 17.3        |\n",
            "|    ep_rew_mean          | 109         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 450         |\n",
            "|    iterations           | 50          |\n",
            "|    time_elapsed         | 227         |\n",
            "|    total_timesteps      | 102400      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026071753 |\n",
            "|    clip_fraction        | 0.3         |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.77       |\n",
            "|    explained_variance   | 0.997       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.1         |\n",
            "|    n_updates            | 490         |\n",
            "|    policy_gradient_loss | -0.0805     |\n",
            "|    value_loss           | 0.82        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 17.4        |\n",
            "|    ep_rew_mean          | 109         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 450         |\n",
            "|    iterations           | 51          |\n",
            "|    time_elapsed         | 231         |\n",
            "|    total_timesteps      | 104448      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025887972 |\n",
            "|    clip_fraction        | 0.308       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.59       |\n",
            "|    explained_variance   | 0.998       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.128       |\n",
            "|    n_updates            | 500         |\n",
            "|    policy_gradient_loss | -0.079      |\n",
            "|    value_loss           | 0.817       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 15.6        |\n",
            "|    ep_rew_mean          | 109         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 449         |\n",
            "|    iterations           | 52          |\n",
            "|    time_elapsed         | 236         |\n",
            "|    total_timesteps      | 106496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024902387 |\n",
            "|    clip_fraction        | 0.289       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.56       |\n",
            "|    explained_variance   | 0.998       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.112       |\n",
            "|    n_updates            | 510         |\n",
            "|    policy_gradient_loss | -0.0737     |\n",
            "|    value_loss           | 0.758       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 16.6       |\n",
            "|    ep_rew_mean          | 109        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 450        |\n",
            "|    iterations           | 53         |\n",
            "|    time_elapsed         | 241        |\n",
            "|    total_timesteps      | 108544     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02270228 |\n",
            "|    clip_fraction        | 0.289      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.42      |\n",
            "|    explained_variance   | 0.998      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.207      |\n",
            "|    n_updates            | 520        |\n",
            "|    policy_gradient_loss | -0.0742    |\n",
            "|    value_loss           | 0.87       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 15          |\n",
            "|    ep_rew_mean          | 109         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 450         |\n",
            "|    iterations           | 54          |\n",
            "|    time_elapsed         | 245         |\n",
            "|    total_timesteps      | 110592      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023190482 |\n",
            "|    clip_fraction        | 0.259       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.43       |\n",
            "|    explained_variance   | 0.997       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.263       |\n",
            "|    n_updates            | 530         |\n",
            "|    policy_gradient_loss | -0.0707     |\n",
            "|    value_loss           | 0.916       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 13.4        |\n",
            "|    ep_rew_mean          | 109         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 55          |\n",
            "|    time_elapsed         | 251         |\n",
            "|    total_timesteps      | 112640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023198048 |\n",
            "|    clip_fraction        | 0.292       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.2        |\n",
            "|    explained_variance   | 0.998       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.153       |\n",
            "|    n_updates            | 540         |\n",
            "|    policy_gradient_loss | -0.072      |\n",
            "|    value_loss           | 0.785       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 13.2        |\n",
            "|    ep_rew_mean          | 109         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 56          |\n",
            "|    time_elapsed         | 256         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023147581 |\n",
            "|    clip_fraction        | 0.277       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.94       |\n",
            "|    explained_variance   | 0.999       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0829      |\n",
            "|    n_updates            | 550         |\n",
            "|    policy_gradient_loss | -0.0678     |\n",
            "|    value_loss           | 0.643       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 12.9        |\n",
            "|    ep_rew_mean          | 109         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 448         |\n",
            "|    iterations           | 57          |\n",
            "|    time_elapsed         | 260         |\n",
            "|    total_timesteps      | 116736      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021763818 |\n",
            "|    clip_fraction        | 0.262       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.88       |\n",
            "|    explained_variance   | 0.999       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.167       |\n",
            "|    n_updates            | 560         |\n",
            "|    policy_gradient_loss | -0.0633     |\n",
            "|    value_loss           | 0.578       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 13.5        |\n",
            "|    ep_rew_mean          | 109         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 58          |\n",
            "|    time_elapsed         | 265         |\n",
            "|    total_timesteps      | 118784      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021700442 |\n",
            "|    clip_fraction        | 0.256       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.74       |\n",
            "|    explained_variance   | 0.998       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.139       |\n",
            "|    n_updates            | 570         |\n",
            "|    policy_gradient_loss | -0.0624     |\n",
            "|    value_loss           | 0.723       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 11.3      |\n",
            "|    ep_rew_mean          | 109       |\n",
            "| time/                   |           |\n",
            "|    fps                  | 447       |\n",
            "|    iterations           | 59        |\n",
            "|    time_elapsed         | 269       |\n",
            "|    total_timesteps      | 120832    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0224877 |\n",
            "|    clip_fraction        | 0.278     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.72     |\n",
            "|    explained_variance   | 0.999     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.114     |\n",
            "|    n_updates            | 580       |\n",
            "|    policy_gradient_loss | -0.0646   |\n",
            "|    value_loss           | 0.495     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 12.4       |\n",
            "|    ep_rew_mean          | 109        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 447        |\n",
            "|    iterations           | 60         |\n",
            "|    time_elapsed         | 274        |\n",
            "|    total_timesteps      | 122880     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02160101 |\n",
            "|    clip_fraction        | 0.269      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.43      |\n",
            "|    explained_variance   | 0.999      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0414     |\n",
            "|    n_updates            | 590        |\n",
            "|    policy_gradient_loss | -0.0596    |\n",
            "|    value_loss           | 0.425      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 11         |\n",
            "|    ep_rew_mean          | 109        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 447        |\n",
            "|    iterations           | 61         |\n",
            "|    time_elapsed         | 279        |\n",
            "|    total_timesteps      | 124928     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02449971 |\n",
            "|    clip_fraction        | 0.263      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.39      |\n",
            "|    explained_variance   | 0.999      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0599     |\n",
            "|    n_updates            | 600        |\n",
            "|    policy_gradient_loss | -0.0567    |\n",
            "|    value_loss           | 0.381      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 12         |\n",
            "|    ep_rew_mean          | 109        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 447        |\n",
            "|    iterations           | 62         |\n",
            "|    time_elapsed         | 283        |\n",
            "|    total_timesteps      | 126976     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01689667 |\n",
            "|    clip_fraction        | 0.209      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.06      |\n",
            "|    explained_variance   | 0.999      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0357     |\n",
            "|    n_updates            | 610        |\n",
            "|    policy_gradient_loss | -0.0463    |\n",
            "|    value_loss           | 0.317      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 11.4        |\n",
            "|    ep_rew_mean          | 109         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 63          |\n",
            "|    time_elapsed         | 288         |\n",
            "|    total_timesteps      | 129024      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022265654 |\n",
            "|    clip_fraction        | 0.222       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.24       |\n",
            "|    explained_variance   | 0.999       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.053       |\n",
            "|    n_updates            | 620         |\n",
            "|    policy_gradient_loss | -0.0514     |\n",
            "|    value_loss           | 0.354       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 10.6       |\n",
            "|    ep_rew_mean          | 109        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 447        |\n",
            "|    iterations           | 64         |\n",
            "|    time_elapsed         | 292        |\n",
            "|    total_timesteps      | 131072     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01837933 |\n",
            "|    clip_fraction        | 0.221      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2         |\n",
            "|    explained_variance   | 0.999      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0305     |\n",
            "|    n_updates            | 630        |\n",
            "|    policy_gradient_loss | -0.0521    |\n",
            "|    value_loss           | 0.319      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 10.8        |\n",
            "|    ep_rew_mean          | 109         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 65          |\n",
            "|    time_elapsed         | 297         |\n",
            "|    total_timesteps      | 133120      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018805217 |\n",
            "|    clip_fraction        | 0.208       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.81       |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0151      |\n",
            "|    n_updates            | 640         |\n",
            "|    policy_gradient_loss | -0.0483     |\n",
            "|    value_loss           | 0.237       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.88        |\n",
            "|    ep_rew_mean          | 109         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 66          |\n",
            "|    time_elapsed         | 302         |\n",
            "|    total_timesteps      | 135168      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017135043 |\n",
            "|    clip_fraction        | 0.189       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.76       |\n",
            "|    explained_variance   | 0.999       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.107       |\n",
            "|    n_updates            | 650         |\n",
            "|    policy_gradient_loss | -0.0446     |\n",
            "|    value_loss           | 0.251       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 9.6        |\n",
            "|    ep_rew_mean          | 109        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 447        |\n",
            "|    iterations           | 67         |\n",
            "|    time_elapsed         | 306        |\n",
            "|    total_timesteps      | 137216     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01785277 |\n",
            "|    clip_fraction        | 0.213      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.63      |\n",
            "|    explained_variance   | 1          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0211     |\n",
            "|    n_updates            | 660        |\n",
            "|    policy_gradient_loss | -0.0452    |\n",
            "|    value_loss           | 0.202      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 10.2        |\n",
            "|    ep_rew_mean          | 109         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 68          |\n",
            "|    time_elapsed         | 310         |\n",
            "|    total_timesteps      | 139264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017515972 |\n",
            "|    clip_fraction        | 0.187       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.47       |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0185     |\n",
            "|    n_updates            | 670         |\n",
            "|    policy_gradient_loss | -0.0449     |\n",
            "|    value_loss           | 0.142       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 10          |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 69          |\n",
            "|    time_elapsed         | 315         |\n",
            "|    total_timesteps      | 141312      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018650487 |\n",
            "|    clip_fraction        | 0.178       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.53       |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00964    |\n",
            "|    n_updates            | 680         |\n",
            "|    policy_gradient_loss | -0.0421     |\n",
            "|    value_loss           | 0.226       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.55        |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 70          |\n",
            "|    time_elapsed         | 320         |\n",
            "|    total_timesteps      | 143360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022549914 |\n",
            "|    clip_fraction        | 0.214       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.33       |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0342     |\n",
            "|    n_updates            | 690         |\n",
            "|    policy_gradient_loss | -0.0473     |\n",
            "|    value_loss           | 0.136       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.26        |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 71          |\n",
            "|    time_elapsed         | 324         |\n",
            "|    total_timesteps      | 145408      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023652624 |\n",
            "|    clip_fraction        | 0.179       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.15       |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.000133   |\n",
            "|    n_updates            | 700         |\n",
            "|    policy_gradient_loss | -0.0401     |\n",
            "|    value_loss           | 0.104       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.91        |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 72          |\n",
            "|    time_elapsed         | 329         |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014213616 |\n",
            "|    clip_fraction        | 0.138       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.06       |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.027      |\n",
            "|    n_updates            | 710         |\n",
            "|    policy_gradient_loss | -0.0353     |\n",
            "|    value_loss           | 0.0849      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.4         |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 73          |\n",
            "|    time_elapsed         | 333         |\n",
            "|    total_timesteps      | 149504      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014178936 |\n",
            "|    clip_fraction        | 0.127       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.932      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0189     |\n",
            "|    n_updates            | 720         |\n",
            "|    policy_gradient_loss | -0.0338     |\n",
            "|    value_loss           | 0.0663      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.1         |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 74          |\n",
            "|    time_elapsed         | 338         |\n",
            "|    total_timesteps      | 151552      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015801167 |\n",
            "|    clip_fraction        | 0.145       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.895      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0166     |\n",
            "|    n_updates            | 730         |\n",
            "|    policy_gradient_loss | -0.0325     |\n",
            "|    value_loss           | 0.0867      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.34        |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 75          |\n",
            "|    time_elapsed         | 343         |\n",
            "|    total_timesteps      | 153600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018440625 |\n",
            "|    clip_fraction        | 0.147       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.828      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0251     |\n",
            "|    n_updates            | 740         |\n",
            "|    policy_gradient_loss | -0.0334     |\n",
            "|    value_loss           | 0.0556      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.5         |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 76          |\n",
            "|    time_elapsed         | 347         |\n",
            "|    total_timesteps      | 155648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018596552 |\n",
            "|    clip_fraction        | 0.167       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.816      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0134     |\n",
            "|    n_updates            | 750         |\n",
            "|    policy_gradient_loss | -0.034      |\n",
            "|    value_loss           | 0.0472      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.79        |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 77          |\n",
            "|    time_elapsed         | 352         |\n",
            "|    total_timesteps      | 157696      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014801597 |\n",
            "|    clip_fraction        | 0.134       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.693      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0199     |\n",
            "|    n_updates            | 760         |\n",
            "|    policy_gradient_loss | -0.0256     |\n",
            "|    value_loss           | 0.0999      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.27        |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 446         |\n",
            "|    iterations           | 78          |\n",
            "|    time_elapsed         | 357         |\n",
            "|    total_timesteps      | 159744      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012097254 |\n",
            "|    clip_fraction        | 0.142       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.66       |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0259     |\n",
            "|    n_updates            | 770         |\n",
            "|    policy_gradient_loss | -0.0321     |\n",
            "|    value_loss           | 0.106       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.61        |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 79          |\n",
            "|    time_elapsed         | 361         |\n",
            "|    total_timesteps      | 161792      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017688036 |\n",
            "|    clip_fraction        | 0.136       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.584      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0637      |\n",
            "|    n_updates            | 780         |\n",
            "|    policy_gradient_loss | -0.0285     |\n",
            "|    value_loss           | 0.0447      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.5         |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 446         |\n",
            "|    iterations           | 80          |\n",
            "|    time_elapsed         | 366         |\n",
            "|    total_timesteps      | 163840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012719355 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.522      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00451     |\n",
            "|    n_updates            | 790         |\n",
            "|    policy_gradient_loss | -0.0255     |\n",
            "|    value_loss           | 0.0405      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 8.87       |\n",
            "|    ep_rew_mean          | 110        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 446        |\n",
            "|    iterations           | 81         |\n",
            "|    time_elapsed         | 371        |\n",
            "|    total_timesteps      | 165888     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01179911 |\n",
            "|    clip_fraction        | 0.0899     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.535     |\n",
            "|    explained_variance   | 1          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0226    |\n",
            "|    n_updates            | 800        |\n",
            "|    policy_gradient_loss | -0.0251    |\n",
            "|    value_loss           | 0.0231     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.52        |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 82          |\n",
            "|    time_elapsed         | 375         |\n",
            "|    total_timesteps      | 167936      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016189551 |\n",
            "|    clip_fraction        | 0.12        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.585      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0176     |\n",
            "|    n_updates            | 810         |\n",
            "|    policy_gradient_loss | -0.0281     |\n",
            "|    value_loss           | 0.0373      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.51        |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 446         |\n",
            "|    iterations           | 83          |\n",
            "|    time_elapsed         | 380         |\n",
            "|    total_timesteps      | 169984      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012557139 |\n",
            "|    clip_fraction        | 0.116       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.517      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0228     |\n",
            "|    n_updates            | 820         |\n",
            "|    policy_gradient_loss | -0.0288     |\n",
            "|    value_loss           | 0.0423      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.48        |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 446         |\n",
            "|    iterations           | 84          |\n",
            "|    time_elapsed         | 385         |\n",
            "|    total_timesteps      | 172032      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009406146 |\n",
            "|    clip_fraction        | 0.0745      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.457      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0236     |\n",
            "|    n_updates            | 830         |\n",
            "|    policy_gradient_loss | -0.0203     |\n",
            "|    value_loss           | 0.0281      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 9            |\n",
            "|    ep_rew_mean          | 110          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 446          |\n",
            "|    iterations           | 85           |\n",
            "|    time_elapsed         | 389          |\n",
            "|    total_timesteps      | 174080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0122989705 |\n",
            "|    clip_fraction        | 0.0783       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.348       |\n",
            "|    explained_variance   | 1            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00234      |\n",
            "|    n_updates            | 840          |\n",
            "|    policy_gradient_loss | -0.0212      |\n",
            "|    value_loss           | 0.0145       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.46        |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 446         |\n",
            "|    iterations           | 86          |\n",
            "|    time_elapsed         | 394         |\n",
            "|    total_timesteps      | 176128      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010465679 |\n",
            "|    clip_fraction        | 0.0794      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.414      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00948    |\n",
            "|    n_updates            | 850         |\n",
            "|    policy_gradient_loss | -0.0226     |\n",
            "|    value_loss           | 0.0879      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.43        |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 446         |\n",
            "|    iterations           | 87          |\n",
            "|    time_elapsed         | 398         |\n",
            "|    total_timesteps      | 178176      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009953387 |\n",
            "|    clip_fraction        | 0.0637      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.293      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00611    |\n",
            "|    n_updates            | 860         |\n",
            "|    policy_gradient_loss | -0.0135     |\n",
            "|    value_loss           | 0.0134      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.53        |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 447         |\n",
            "|    iterations           | 88          |\n",
            "|    time_elapsed         | 403         |\n",
            "|    total_timesteps      | 180224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010874798 |\n",
            "|    clip_fraction        | 0.0583      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.307      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0252     |\n",
            "|    n_updates            | 870         |\n",
            "|    policy_gradient_loss | -0.0181     |\n",
            "|    value_loss           | 0.00928     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.19        |\n",
            "|    ep_rew_mean          | 109         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 446         |\n",
            "|    iterations           | 89          |\n",
            "|    time_elapsed         | 408         |\n",
            "|    total_timesteps      | 182272      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011083312 |\n",
            "|    clip_fraction        | 0.0663      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.354      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0117      |\n",
            "|    n_updates            | 880         |\n",
            "|    policy_gradient_loss | -0.0166     |\n",
            "|    value_loss           | 0.00973     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.97        |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 446         |\n",
            "|    iterations           | 90          |\n",
            "|    time_elapsed         | 412         |\n",
            "|    total_timesteps      | 184320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012950171 |\n",
            "|    clip_fraction        | 0.131       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.439      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00809    |\n",
            "|    n_updates            | 890         |\n",
            "|    policy_gradient_loss | -0.0348     |\n",
            "|    value_loss           | 0.108       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 8.62         |\n",
            "|    ep_rew_mean          | 109          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 446          |\n",
            "|    iterations           | 91           |\n",
            "|    time_elapsed         | 416          |\n",
            "|    total_timesteps      | 186368       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0155515075 |\n",
            "|    clip_fraction        | 0.0974       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.339       |\n",
            "|    explained_variance   | 1            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00268     |\n",
            "|    n_updates            | 900          |\n",
            "|    policy_gradient_loss | -0.0274      |\n",
            "|    value_loss           | 0.0313       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 8.15         |\n",
            "|    ep_rew_mean          | 110          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 446          |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 421          |\n",
            "|    total_timesteps      | 188416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065384833 |\n",
            "|    clip_fraction        | 0.0617       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.222       |\n",
            "|    explained_variance   | 1            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0247      |\n",
            "|    n_updates            | 910          |\n",
            "|    policy_gradient_loss | -0.0212      |\n",
            "|    value_loss           | 0.0494       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 8.1          |\n",
            "|    ep_rew_mean          | 110          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 446          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 426          |\n",
            "|    total_timesteps      | 190464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069357306 |\n",
            "|    clip_fraction        | 0.0367       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.176       |\n",
            "|    explained_variance   | 1            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00838     |\n",
            "|    n_updates            | 920          |\n",
            "|    policy_gradient_loss | -0.0113      |\n",
            "|    value_loss           | 0.0044       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.31        |\n",
            "|    ep_rew_mean          | 109         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 446         |\n",
            "|    iterations           | 94          |\n",
            "|    time_elapsed         | 430         |\n",
            "|    total_timesteps      | 192512      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021916382 |\n",
            "|    clip_fraction        | 0.0919      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.304      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00206    |\n",
            "|    n_updates            | 930         |\n",
            "|    policy_gradient_loss | -0.0137     |\n",
            "|    value_loss           | 0.0596      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.06        |\n",
            "|    ep_rew_mean          | 109         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 446         |\n",
            "|    iterations           | 95          |\n",
            "|    time_elapsed         | 435         |\n",
            "|    total_timesteps      | 194560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019292764 |\n",
            "|    clip_fraction        | 0.135       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.446      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00213     |\n",
            "|    n_updates            | 940         |\n",
            "|    policy_gradient_loss | -0.0273     |\n",
            "|    value_loss           | 0.137       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 8.03       |\n",
            "|    ep_rew_mean          | 109        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 446        |\n",
            "|    iterations           | 96         |\n",
            "|    time_elapsed         | 439        |\n",
            "|    total_timesteps      | 196608     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02197503 |\n",
            "|    clip_fraction        | 0.151      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.343     |\n",
            "|    explained_variance   | 1          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.031     |\n",
            "|    n_updates            | 950        |\n",
            "|    policy_gradient_loss | -0.033     |\n",
            "|    value_loss           | 0.0425     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.33        |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 446         |\n",
            "|    iterations           | 97          |\n",
            "|    time_elapsed         | 444         |\n",
            "|    total_timesteps      | 198656      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025559478 |\n",
            "|    clip_fraction        | 0.105       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.291      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00328     |\n",
            "|    n_updates            | 960         |\n",
            "|    policy_gradient_loss | -0.0214     |\n",
            "|    value_loss           | 0.034       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.28        |\n",
            "|    ep_rew_mean          | 110         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 446         |\n",
            "|    iterations           | 98          |\n",
            "|    time_elapsed         | 449         |\n",
            "|    total_timesteps      | 200704      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019097896 |\n",
            "|    clip_fraction        | 0.0793      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.334      |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00979    |\n",
            "|    n_updates            | 970         |\n",
            "|    policy_gradient_loss | -0.0184     |\n",
            "|    value_loss           | 0.0239      |\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def save_small_model_encoder():\n",
        "    env = SmallDroneEnv()\n",
        "    model = PPO(\"MlpPolicy\", env, verbose=0)\n",
        "    model.learn(total_timesteps=200000)\n",
        "\n",
        "    # The progressive training strategy extracts the weights of the middle layer (hidden layer)\n",
        "    encoder_state = {\n",
        "        k: v for k, v in model.policy.mlp_extractor.state_dict().items()\n",
        "        if \"1\" in k or \"2\" in k  # Only retain the parameters of the second layer and beyond (skip the input layer)\n",
        "    }\n",
        "    torch.save(encoder_state, \"small_encoder_hidden.pt\")\n",
        "    model.save(\"ppo_small_model_1\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_large_model_with_transfer():\n",
        "    env = DronePlacementEnv()\n",
        "\n",
        "    policy_kwargs = dict(net_arch=[dict(pi=[64, 64], vf=[64, 64])])\n",
        "    model = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=1)\n",
        "\n",
        "    # Load hidden layer parameters\n",
        "    encoder_weights = torch.load(\"small_encoder_hidden.pt\")\n",
        "    model.policy.mlp_extractor.load_state_dict(encoder_weights, strict=False)\n",
        "\n",
        "    model.learn(total_timesteps=200000)\n",
        "    model.save(\"ppo_large_model_1\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    save_small_model_encoder()\n",
        "    train_large_model_with_transfer()    # Migrate the encoder to the large map to continue training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrqhoG-0BbZo",
        "outputId": "07c89917-22f5-4339-f90a-c02dd5598e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0: Placed 5x5 drone at (3, 3), reward: 24.60\n",
            "[[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1  0  1  0  1  0 -1 -1 -1 -1]\n",
            " [-1  0  1  0  1  1 -1 -1 -1 -1]\n",
            " [-1  1  1  1  1  1 -1 -1 -1 -1]\n",
            " [-1  1  1  1  1  1 -1 -1 -1 -1]\n",
            " [-1  1  1  0  1  0 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
            "Step 1: Placed 5x5 drone at (7, 8), reward: 19.90\n",
            "[[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1  0  1  0  1  0 -1 -1 -1 -1]\n",
            " [-1  0  1  0  1  1 -1 -1 -1 -1]\n",
            " [-1  1  1  1  1  1 -1 -1 -1 -1]\n",
            " [-1  1  1  1  1  1 -1 -1 -1 -1]\n",
            " [-1  1  1  0  1  0  0  0  1  1]\n",
            " [-1 -1 -1 -1 -1 -1  1  1  0  1]\n",
            " [-1 -1 -1 -1 -1 -1  1  1  1  1]\n",
            " [-1 -1 -1 -1 -1 -1  0  1  1  1]\n",
            " [-1 -1 -1 -1 -1 -1  0  1  1  1]]\n",
            "Step 2: Placed 5x5 drone at (8, 3), reward: 19.90\n",
            "[[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1  0  1  0  1  0 -1 -1 -1 -1]\n",
            " [-1  0  1  0  1  1 -1 -1 -1 -1]\n",
            " [-1  1  1  1  1  1 -1 -1 -1 -1]\n",
            " [-1  1  1  1  1  1 -1 -1 -1 -1]\n",
            " [-1  1  1  0  1  0  0  0  1  1]\n",
            " [-1  0  1  1  1  0  1  1  0  1]\n",
            " [-1  1  1  1  1  1  1  1  1  1]\n",
            " [-1  1  0  1  1  1  0  1  1  1]\n",
            " [-1  1  1  1  0  1  0  1  1  1]]\n",
            "Step 3: Placed 5x5 drone at (2, 8), reward: 19.90\n",
            "[[-1 -1 -1 -1 -1 -1  0  1  1  0]\n",
            " [-1  0  1  0  1  0  1  1  0  0]\n",
            " [-1  0  1  0  1  1  1  1  1  1]\n",
            " [-1  1  1  1  1  1  1  1  1  1]\n",
            " [-1  1  1  1  1  1  1  0  1  1]\n",
            " [-1  1  1  0  1  0  0  0  1  1]\n",
            " [-1  0  1  1  1  0  1  1  0  1]\n",
            " [-1  1  1  1  1  1  1  1  1  1]\n",
            " [-1  1  0  1  1  1  0  1  1  1]\n",
            " [-1  1  1  1  0  1  0  1  1  1]]\n",
            "Step 4: Placed 5x5 drone at (1, 2), reward: 7.90\n",
            "[[ 1  0  1  1  0 -1  0  1  1  0]\n",
            " [ 1  0  1  0  1  0  1  1  0  0]\n",
            " [ 1  0  1  0  1  1  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [-1  1  1  1  1  1  1  0  1  1]\n",
            " [-1  1  1  0  1  0  0  0  1  1]\n",
            " [-1  0  1  1  1  0  1  1  0  1]\n",
            " [-1  1  1  1  1  1  1  1  1  1]\n",
            " [-1  1  0  1  1  1  0  1  1  1]\n",
            " [-1  1  1  1  0  1  0  1  1  1]]\n",
            "Step 5: Placed 3x3 drone at (5, 1), reward: 3.10\n",
            "[[ 1  0  1  1  0 -1  0  1  1  0]\n",
            " [ 1  0  1  0  1  0  1  1  0  0]\n",
            " [ 1  0  1  0  1  1  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  0  1  1]\n",
            " [ 1  1  1  0  1  0  0  0  1  1]\n",
            " [ 1  0  1  1  1  0  1  1  0  1]\n",
            " [-1  1  1  1  1  1  1  1  1  1]\n",
            " [-1  1  0  1  1  1  0  1  1  1]\n",
            " [-1  1  1  1  0  1  0  1  1  1]]\n",
            "Step 6: Placed 3x3 drone at (8, 1), reward: 3.10\n",
            "[[ 1  0  1  1  0 -1  0  1  1  0]\n",
            " [ 1  0  1  0  1  0  1  1  0  0]\n",
            " [ 1  0  1  0  1  1  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  0  1  1]\n",
            " [ 1  1  1  0  1  0  0  0  1  1]\n",
            " [ 1  0  1  1  1  0  1  1  0  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  0  1  1  1  0  1  1  1]\n",
            " [ 1  1  1  1  0  1  0  1  1  1]]\n",
            "Step 7: Placed 3x3 drone at (0, 5), reward: 11.10\n",
            "[[1 0 1 1 0 1 0 1 1 0]\n",
            " [1 0 1 0 1 0 1 1 0 0]\n",
            " [1 0 1 0 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 0 1 1]\n",
            " [1 1 1 0 1 0 0 0 1 1]\n",
            " [1 0 1 1 1 0 1 1 0 1]\n",
            " [1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 0 1 1 1 0 1 1 1]\n",
            " [1 1 1 1 0 1 0 1 1 1]]\n",
            "ðŸŽ‰ Mission Complete: All cells explored!\n"
          ]
        }
      ],
      "source": [
        "def run_trained_model():\n",
        "    model = PPO.load(\"ppo_large_model_1\")\n",
        "    env = DronePlacementEnv()\n",
        "    obs, _ = env.reset()\n",
        "\n",
        "    for step in range(env.max_steps):\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, reward, terminated, truncated, _ = env.step(action)\n",
        "        x = action // 20\n",
        "        y = (action % 20) // 2\n",
        "        drone_type = \"3x3\" if action % 2 == 0 else \"5x5\"\n",
        "        print(f\"Step {step}: Placed {drone_type} drone at ({x}, {y}), reward: {reward:.2f}\")\n",
        "        env.render()\n",
        "        if terminated or truncated:\n",
        "            print(\"Mission Complete: All cells explored!\")\n",
        "            break\n",
        "        if truncated:\n",
        "            print(\"Max steps reached.\")\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_trained_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4FCkb3JI-A2"
      },
      "source": [
        "# Env 2: Env 1 + Static grid, high-priority zones, battery cost, discovering priority SAFE cells. Resultâ‰ˆ14-53steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69An_wWWamkK",
        "outputId": "311a9476-5d2c-438f-c6f1-2dcb641a643d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random rollout reward: 65.25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/env_checker.py:272: UserWarning: Your observation  has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "PRIORITY = 2        # \"high-value grids\"\n",
        "MOVE_COST = 1        # Each next action consumes 1 grid of power\n",
        "COMM_RANGE = 3        # Single hop communication radius (Manhattan)\n",
        "\n",
        "class AdvancedDroneEnv(DronePlacementEnv):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        grid_size: int = 10,\n",
        "        max_steps: int = 50,\n",
        "        init_battery: int = 60,        # total power\n",
        "        priority_prob: float = 0.1       # Random high-value lattice probability\n",
        "    ):\n",
        "        self.init_battery = init_battery\n",
        "        self.priority_prob = priority_prob\n",
        "        super().__init__(grid_size=grid_size, max_steps=max_steps)\n",
        "        self.action_space = spaces.Discrete(grid_size * grid_size * 4)\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        obs, info = super().reset(seed=seed)\n",
        "        self.battery = self.init_battery\n",
        "        self.priority_map = self._init_priority_map()\n",
        "        self.discovered_priority = np.zeros_like(self.priority_map, dtype=bool)\n",
        "        return obs, info\n",
        "\n",
        "    def _init_priority_map(self):\n",
        "        # 1 = highâ€‘priority SAFE\n",
        "        pr_map = np.zeros_like(self.actual_env, dtype=np.int8)\n",
        "        mask = (self.actual_env == SAFE) & (np.random.rand(*self.actual_env.shape) < self.priority_prob)\n",
        "        pr_map[mask] = 1\n",
        "        return pr_map\n",
        "\n",
        "    def step(self, action):\n",
        "        # Parse the action\n",
        "        self.battery -= MOVE_COST\n",
        "        role_bit = action % 2          # 0=explorer 1=relay\n",
        "        pure_action = action // 2\n",
        "        grid_action_space = self.grid_size * self.grid_size * 2\n",
        "        assert pure_action < grid_action_space, \"Action decode OOB\"\n",
        "\n",
        "        obs, base_reward, terminated, truncated, info = super().step(pure_action)\n",
        "\n",
        "        # Discover the priority case\n",
        "        new_priority = self._discover_cells()\n",
        "        bonus_priority = 2 * new_priority\n",
        "        base_reward += bonus_priority\n",
        "\n",
        "        # Communication reward/penalty\n",
        "        comm_ok = self._is_connected(role_bit, pure_action)\n",
        "        base_reward += 1.0 if comm_ok else -1.0\n",
        "        # Charge terminates\n",
        "        if self.battery <= 0:\n",
        "            truncated = True\n",
        "\n",
        "        # End rewards to remaining power\n",
        "        if terminated:\n",
        "            base_reward += 0.05 * self.battery\n",
        "        return obs, base_reward, terminated, truncated, info\n",
        "\n",
        "    def _discover_cells(self):\n",
        "        newly_found = 0\n",
        "        undiscovered = ~self.discovered_priority & (self.global_grid == SAFE) & (self.priority_map == 1)\n",
        "        newly_found = np.sum(undiscovered)\n",
        "        self.discovered_priority |= undiscovered\n",
        "        return newly_found\n",
        "\n",
        "    # Communication connectivity\n",
        "    def _is_connected(self, role_bit, pure_action):\n",
        "        if role_bit == 1:\n",
        "            pass\n",
        "\n",
        "        # Collect positions of explorer drones\n",
        "        explorers = []\n",
        "        action_per_row = self.grid_size * 2\n",
        "        x = pure_action // action_per_row\n",
        "        y = (pure_action % action_per_row) // 2\n",
        "        drone_type = pure_action % 2\n",
        "        explorers.append((x, y))\n",
        "\n",
        "        base = (0, 0)\n",
        "        for ex in explorers:\n",
        "            if abs(ex[0] - base[0]) + abs(ex[1] - base[1]) > COMM_RANGE:\n",
        "                # If any explorer is too far from base (without a relay), assume disconnected\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def render(self):\n",
        "        print(self.global_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQvEjxh6aLzy",
        "outputId": "66a35a9b-17a8-4207-b0f1-47a693a4dbd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage 1: Training on small grid\n",
            "Using cuda device\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 12.9     |\n",
            "|    ep_rew_mean     | 45.3     |\n",
            "| time/              |          |\n",
            "|    fps             | 2317     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 8192     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 10.9        |\n",
            "|    ep_rew_mean          | 49          |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1222        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 13          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026783219 |\n",
            "|    clip_fraction        | 0.21        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.95       |\n",
            "|    explained_variance   | -0.017      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 17.4        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0455     |\n",
            "|    value_loss           | 132         |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 9.91       |\n",
            "|    ep_rew_mean          | 50.8       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 1058       |\n",
            "|    iterations           | 3          |\n",
            "|    time_elapsed         | 23         |\n",
            "|    total_timesteps      | 24576      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.04707211 |\n",
            "|    clip_fraction        | 0.314      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.84      |\n",
            "|    explained_variance   | 0.763      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 6.05       |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.0561    |\n",
            "|    value_loss           | 19.2       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 9.34      |\n",
            "|    ep_rew_mean          | 51.9      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 968       |\n",
            "|    iterations           | 4         |\n",
            "|    time_elapsed         | 33        |\n",
            "|    total_timesteps      | 32768     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0235675 |\n",
            "|    clip_fraction        | 0.369     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -4.72     |\n",
            "|    explained_variance   | 0.928     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 4.12      |\n",
            "|    n_updates            | 30        |\n",
            "|    policy_gradient_loss | -0.0672   |\n",
            "|    value_loss           | 8.44      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.63        |\n",
            "|    ep_rew_mean          | 52.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 955         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 42          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022573583 |\n",
            "|    clip_fraction        | 0.389       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.61       |\n",
            "|    explained_variance   | 0.947       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.77        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0665     |\n",
            "|    value_loss           | 7.24        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 10         |\n",
            "|    ep_rew_mean          | 53.7       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 932        |\n",
            "|    iterations           | 6          |\n",
            "|    time_elapsed         | 52         |\n",
            "|    total_timesteps      | 49152      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02312105 |\n",
            "|    clip_fraction        | 0.399      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.48      |\n",
            "|    explained_variance   | 0.955      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.89       |\n",
            "|    n_updates            | 50         |\n",
            "|    policy_gradient_loss | -0.0675    |\n",
            "|    value_loss           | 6.44       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 11.2       |\n",
            "|    ep_rew_mean          | 55.3       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 916        |\n",
            "|    iterations           | 7          |\n",
            "|    time_elapsed         | 62         |\n",
            "|    total_timesteps      | 57344      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02171256 |\n",
            "|    clip_fraction        | 0.376      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.36      |\n",
            "|    explained_variance   | 0.952      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.99       |\n",
            "|    n_updates            | 60         |\n",
            "|    policy_gradient_loss | -0.0652    |\n",
            "|    value_loss           | 6.91       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 14.2        |\n",
            "|    ep_rew_mean          | 57.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 905         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 72          |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020412525 |\n",
            "|    clip_fraction        | 0.339       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.15       |\n",
            "|    explained_variance   | 0.94        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.09        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0604     |\n",
            "|    value_loss           | 8.21        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 15.4        |\n",
            "|    ep_rew_mean          | 58.1        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 903         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 81          |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017986326 |\n",
            "|    clip_fraction        | 0.293       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.01       |\n",
            "|    explained_variance   | 0.918       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.5         |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0545     |\n",
            "|    value_loss           | 10.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 19.6        |\n",
            "|    ep_rew_mean          | 57.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 896         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 91          |\n",
            "|    total_timesteps      | 81920       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015898366 |\n",
            "|    clip_fraction        | 0.241       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.88       |\n",
            "|    explained_variance   | 0.899       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.29        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0491     |\n",
            "|    value_loss           | 12.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 21.7        |\n",
            "|    ep_rew_mean          | 58.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 888         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 101         |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015212808 |\n",
            "|    clip_fraction        | 0.216       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.75       |\n",
            "|    explained_variance   | 0.88        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.28        |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0462     |\n",
            "|    value_loss           | 14.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 25          |\n",
            "|    ep_rew_mean          | 59.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 885         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 111         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013910646 |\n",
            "|    clip_fraction        | 0.205       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.64       |\n",
            "|    explained_variance   | 0.857       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.02        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0435     |\n",
            "|    value_loss           | 16.8        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 25.7         |\n",
            "|    ep_rew_mean          | 59.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 884          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 120          |\n",
            "|    total_timesteps      | 106496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0143470755 |\n",
            "|    clip_fraction        | 0.196        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.6         |\n",
            "|    explained_variance   | 0.855        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.02         |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.0394      |\n",
            "|    value_loss           | 17.1         |\n",
            "------------------------------------------\n",
            "Stage 1 model and encoder saved.\n",
            "\n",
            " Stage 2: Transfer learning on large grid\n",
            "Using cuda device\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 37.8     |\n",
            "|    ep_rew_mean     | 92.9     |\n",
            "| time/              |          |\n",
            "|    fps             | 2360     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 8192     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 36.4        |\n",
            "|    ep_rew_mean          | 92.7        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1232        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 13          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.038035825 |\n",
            "|    clip_fraction        | 0.243       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.95       |\n",
            "|    explained_variance   | -0.000574   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 57.6        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.068      |\n",
            "|    value_loss           | 315         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 35.5        |\n",
            "|    ep_rew_mean          | 95.5        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1077        |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 22          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020652223 |\n",
            "|    clip_fraction        | 0.208       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.69       |\n",
            "|    explained_variance   | 0.573       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 29.8        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0631     |\n",
            "|    value_loss           | 154         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 33          |\n",
            "|    ep_rew_mean          | 97.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1018        |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 32          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017003449 |\n",
            "|    clip_fraction        | 0.2         |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.72       |\n",
            "|    explained_variance   | 0.747       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 44.6        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0644     |\n",
            "|    value_loss           | 94.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 34.4        |\n",
            "|    ep_rew_mean          | 98.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 977         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018643621 |\n",
            "|    clip_fraction        | 0.229       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.73       |\n",
            "|    explained_variance   | 0.829       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 21.2        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0687     |\n",
            "|    value_loss           | 57          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 33.3        |\n",
            "|    ep_rew_mean          | 99.7        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 949         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 51          |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020708768 |\n",
            "|    clip_fraction        | 0.273       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.72       |\n",
            "|    explained_variance   | 0.897       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 11.3        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0798     |\n",
            "|    value_loss           | 32.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 29.5        |\n",
            "|    ep_rew_mean          | 103         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 940         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 60          |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020111226 |\n",
            "|    clip_fraction        | 0.259       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.7        |\n",
            "|    explained_variance   | 0.923       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.07        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0792     |\n",
            "|    value_loss           | 26.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 27.9        |\n",
            "|    ep_rew_mean          | 106         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 928         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 70          |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020392966 |\n",
            "|    clip_fraction        | 0.27        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.7        |\n",
            "|    explained_variance   | 0.937       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.2        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0821     |\n",
            "|    value_loss           | 21.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 26.9        |\n",
            "|    ep_rew_mean          | 107         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 917         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 80          |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021557733 |\n",
            "|    clip_fraction        | 0.275       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.68       |\n",
            "|    explained_variance   | 0.944       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.59        |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0836     |\n",
            "|    value_loss           | 20.9        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 25.4       |\n",
            "|    ep_rew_mean          | 109        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 906        |\n",
            "|    iterations           | 10         |\n",
            "|    time_elapsed         | 90         |\n",
            "|    total_timesteps      | 81920      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02334312 |\n",
            "|    clip_fraction        | 0.302      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -5.64      |\n",
            "|    explained_variance   | 0.953      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 7.21       |\n",
            "|    n_updates            | 90         |\n",
            "|    policy_gradient_loss | -0.0878    |\n",
            "|    value_loss           | 18.8       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 26.7        |\n",
            "|    ep_rew_mean          | 109         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 901         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 99          |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023312716 |\n",
            "|    clip_fraction        | 0.31        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.6        |\n",
            "|    explained_variance   | 0.958       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.68        |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0879     |\n",
            "|    value_loss           | 17.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 25.4        |\n",
            "|    ep_rew_mean          | 111         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 896         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 109         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024082122 |\n",
            "|    clip_fraction        | 0.32        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.53       |\n",
            "|    explained_variance   | 0.958       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.87        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0879     |\n",
            "|    value_loss           | 17.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 23.7        |\n",
            "|    ep_rew_mean          | 113         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 891         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 119         |\n",
            "|    total_timesteps      | 106496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025041223 |\n",
            "|    clip_fraction        | 0.332       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.49       |\n",
            "|    explained_variance   | 0.969       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.9         |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0889     |\n",
            "|    value_loss           | 14.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 23.6        |\n",
            "|    ep_rew_mean          | 113         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 879         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 130         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024459302 |\n",
            "|    clip_fraction        | 0.323       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.45       |\n",
            "|    explained_variance   | 0.968       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.61        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0876     |\n",
            "|    value_loss           | 15          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 21.7        |\n",
            "|    ep_rew_mean          | 115         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 881         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 139         |\n",
            "|    total_timesteps      | 122880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025166228 |\n",
            "|    clip_fraction        | 0.335       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.39       |\n",
            "|    explained_variance   | 0.969       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.12        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0883     |\n",
            "|    value_loss           | 14.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 22.2        |\n",
            "|    ep_rew_mean          | 117         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 877         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 149         |\n",
            "|    total_timesteps      | 131072      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025311656 |\n",
            "|    clip_fraction        | 0.344       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.31       |\n",
            "|    explained_variance   | 0.972       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.06        |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0891     |\n",
            "|    value_loss           | 14.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 22          |\n",
            "|    ep_rew_mean          | 117         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 875         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 159         |\n",
            "|    total_timesteps      | 139264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025439993 |\n",
            "|    clip_fraction        | 0.344       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.14       |\n",
            "|    explained_variance   | 0.974       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.21        |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0865     |\n",
            "|    value_loss           | 12.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 22.9        |\n",
            "|    ep_rew_mean          | 121         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 872         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 168         |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025737626 |\n",
            "|    clip_fraction        | 0.351       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.05       |\n",
            "|    explained_variance   | 0.974       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.93        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0856     |\n",
            "|    value_loss           | 12.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 22.6        |\n",
            "|    ep_rew_mean          | 121         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 873         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 178         |\n",
            "|    total_timesteps      | 155648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026549987 |\n",
            "|    clip_fraction        | 0.375       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.86       |\n",
            "|    explained_variance   | 0.978       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.68        |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.0854     |\n",
            "|    value_loss           | 11          |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 22.6       |\n",
            "|    ep_rew_mean          | 122        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 871        |\n",
            "|    iterations           | 20         |\n",
            "|    time_elapsed         | 187        |\n",
            "|    total_timesteps      | 163840     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02651107 |\n",
            "|    clip_fraction        | 0.369      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.68      |\n",
            "|    explained_variance   | 0.978      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 5.66       |\n",
            "|    n_updates            | 190        |\n",
            "|    policy_gradient_loss | -0.0829    |\n",
            "|    value_loss           | 11.6       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 24.1        |\n",
            "|    ep_rew_mean          | 123         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 869         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 197         |\n",
            "|    total_timesteps      | 172032      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026453223 |\n",
            "|    clip_fraction        | 0.365       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.55       |\n",
            "|    explained_variance   | 0.977       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.71        |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.0809     |\n",
            "|    value_loss           | 11.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 26          |\n",
            "|    ep_rew_mean          | 126         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 868         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 207         |\n",
            "|    total_timesteps      | 180224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025718585 |\n",
            "|    clip_fraction        | 0.335       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.31       |\n",
            "|    explained_variance   | 0.975       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.82        |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0746     |\n",
            "|    value_loss           | 12.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 28.6        |\n",
            "|    ep_rew_mean          | 129         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 868         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 216         |\n",
            "|    total_timesteps      | 188416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024295952 |\n",
            "|    clip_fraction        | 0.313       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.04       |\n",
            "|    explained_variance   | 0.97        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.32        |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.0716     |\n",
            "|    value_loss           | 13.6        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 31.7       |\n",
            "|    ep_rew_mean          | 130        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 867        |\n",
            "|    iterations           | 24         |\n",
            "|    time_elapsed         | 226        |\n",
            "|    total_timesteps      | 196608     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02207173 |\n",
            "|    clip_fraction        | 0.29       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.88      |\n",
            "|    explained_variance   | 0.965      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 7.72       |\n",
            "|    n_updates            | 230        |\n",
            "|    policy_gradient_loss | -0.0667    |\n",
            "|    value_loss           | 15.1       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 34.6        |\n",
            "|    ep_rew_mean          | 132         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 865         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 236         |\n",
            "|    total_timesteps      | 204800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022582933 |\n",
            "|    clip_fraction        | 0.287       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.76       |\n",
            "|    explained_variance   | 0.959       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.74        |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0654     |\n",
            "|    value_loss           | 15.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 32.3        |\n",
            "|    ep_rew_mean          | 133         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 865         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 246         |\n",
            "|    total_timesteps      | 212992      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020683736 |\n",
            "|    clip_fraction        | 0.252       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.46       |\n",
            "|    explained_variance   | 0.951       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.91        |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.0603     |\n",
            "|    value_loss           | 19.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 37.6        |\n",
            "|    ep_rew_mean          | 136         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 865         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 255         |\n",
            "|    total_timesteps      | 221184      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018720904 |\n",
            "|    clip_fraction        | 0.234       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.47       |\n",
            "|    explained_variance   | 0.946       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.6        |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.056      |\n",
            "|    value_loss           | 21.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 40.9        |\n",
            "|    ep_rew_mean          | 136         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 864         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 265         |\n",
            "|    total_timesteps      | 229376      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019923259 |\n",
            "|    clip_fraction        | 0.237       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.35       |\n",
            "|    explained_variance   | 0.944       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.06        |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.0561     |\n",
            "|    value_loss           | 20.2        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 42.4       |\n",
            "|    ep_rew_mean          | 137        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 862        |\n",
            "|    iterations           | 29         |\n",
            "|    time_elapsed         | 275        |\n",
            "|    total_timesteps      | 237568     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01982587 |\n",
            "|    clip_fraction        | 0.248      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.45      |\n",
            "|    explained_variance   | 0.941      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 9.53       |\n",
            "|    n_updates            | 280        |\n",
            "|    policy_gradient_loss | -0.0571    |\n",
            "|    value_loss           | 21.3       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 42.6        |\n",
            "|    ep_rew_mean          | 137         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 863         |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 284         |\n",
            "|    total_timesteps      | 245760      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020243771 |\n",
            "|    clip_fraction        | 0.253       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.31       |\n",
            "|    explained_variance   | 0.934       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.3         |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.0555     |\n",
            "|    value_loss           | 22.7        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 46         |\n",
            "|    ep_rew_mean          | 139        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 863        |\n",
            "|    iterations           | 31         |\n",
            "|    time_elapsed         | 294        |\n",
            "|    total_timesteps      | 253952     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01843107 |\n",
            "|    clip_fraction        | 0.231      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.34      |\n",
            "|    explained_variance   | 0.929      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 12.4       |\n",
            "|    n_updates            | 300        |\n",
            "|    policy_gradient_loss | -0.0535    |\n",
            "|    value_loss           | 24.7       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 49.9       |\n",
            "|    ep_rew_mean          | 140        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 862        |\n",
            "|    iterations           | 32         |\n",
            "|    time_elapsed         | 304        |\n",
            "|    total_timesteps      | 262144     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01914867 |\n",
            "|    clip_fraction        | 0.231      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.11      |\n",
            "|    explained_variance   | 0.928      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 10.8       |\n",
            "|    n_updates            | 310        |\n",
            "|    policy_gradient_loss | -0.0524    |\n",
            "|    value_loss           | 23.4       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 53.7        |\n",
            "|    ep_rew_mean          | 144         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 861         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 313         |\n",
            "|    total_timesteps      | 270336      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017453244 |\n",
            "|    clip_fraction        | 0.211       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.99       |\n",
            "|    explained_variance   | 0.93        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.68        |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -0.0475     |\n",
            "|    value_loss           | 22.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | 141         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 862         |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 323         |\n",
            "|    total_timesteps      | 278528      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017203253 |\n",
            "|    clip_fraction        | 0.212       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.79       |\n",
            "|    explained_variance   | 0.938       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.38        |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | -0.0472     |\n",
            "|    value_loss           | 20.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 52.2        |\n",
            "|    ep_rew_mean          | 142         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 861         |\n",
            "|    iterations           | 35          |\n",
            "|    time_elapsed         | 332         |\n",
            "|    total_timesteps      | 286720      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017898146 |\n",
            "|    clip_fraction        | 0.218       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.97       |\n",
            "|    explained_variance   | 0.919       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.65        |\n",
            "|    n_updates            | 340         |\n",
            "|    policy_gradient_loss | -0.0493     |\n",
            "|    value_loss           | 23.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 53.7        |\n",
            "|    ep_rew_mean          | 144         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 860         |\n",
            "|    iterations           | 36          |\n",
            "|    time_elapsed         | 342         |\n",
            "|    total_timesteps      | 294912      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017662318 |\n",
            "|    clip_fraction        | 0.22        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.99       |\n",
            "|    explained_variance   | 0.925       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.7        |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | -0.0481     |\n",
            "|    value_loss           | 23          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 54.7        |\n",
            "|    ep_rew_mean          | 144         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 859         |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 352         |\n",
            "|    total_timesteps      | 303104      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017248135 |\n",
            "|    clip_fraction        | 0.209       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.8        |\n",
            "|    explained_variance   | 0.926       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.22        |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | -0.0476     |\n",
            "|    value_loss           | 22.6        |\n",
            "-----------------------------------------\n",
            "Stage 2 training complete.\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "# Stage 1: Train on Small Grid\n",
        "def train_stage1_small():\n",
        "    print(\"Stage 1: Training on small grid\")\n",
        "    env = make_vec_env(lambda: AdvancedDroneEnv(grid_size=6, max_steps=30, init_battery=40), n_envs=4)\n",
        "\n",
        "    model = PPO(\"MlpPolicy\", env,\n",
        "                verbose=1,\n",
        "                device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "                policy_kwargs=dict(net_arch=[dict(pi=[64, 64], vf=[64, 64])]))\n",
        "    model.learn(total_timesteps=100_000)\n",
        "    model.save(\"ppo_smallmap_advanced_model_2\")\n",
        "\n",
        "    # Extract hidden layers\n",
        "    encoder_state = {\n",
        "        k: v for k, v in model.policy.mlp_extractor.state_dict().items()\n",
        "        if not k.startswith(\"policy_net.0\") and not k.startswith(\"value_net.0\")\n",
        "    }\n",
        "    torch.save(encoder_state, \"encoder_stage1.pt\")\n",
        "    print(\"Stage 1 model and encoder saved.\")\n",
        "\n",
        "# Stage 2: Train on Large Grid with Transferred Features\n",
        "def train_stage2_big():\n",
        "    print(\"\\n Stage 2: Transfer learning on large grid\")\n",
        "    env = make_vec_env(lambda: AdvancedDroneEnv(grid_size=10, max_steps=60, init_battery=80), n_envs=4)\n",
        "\n",
        "    model = PPO(\"MlpPolicy\", env,\n",
        "                verbose=1,\n",
        "                device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "                policy_kwargs=dict(net_arch=[dict(pi=[64, 64], vf=[64, 64])]))\n",
        "\n",
        "    # Load transferred hidden layers\n",
        "    encoder_state = torch.load(\"encoder_stage1.pt\")\n",
        "    model.policy.mlp_extractor.load_state_dict(encoder_state, strict=False)\n",
        "\n",
        "    model.learn(total_timesteps=300_000)\n",
        "    model.save(\"ppo_bigmap_advanced_model_2\")\n",
        "    print(\"Stage 2 training complete.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_stage1_small()\n",
        "    train_stage2_big()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "npTnczw4c1qT",
        "outputId": "2b8be937-92a5-4e67-c420-228b79039c0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0: Placed 3x3 drone at (15, 7), reward: 24.90\n",
            "[[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1  0  1  1  0]\n",
            " [-1 -1 -1 -1 -1 -1  1  0  1  1]\n",
            " [-1 -1 -1 -1 -1 -1  1  1  1  1]\n",
            " [-1 -1 -1 -1 -1 -1  1  1  1  1]\n",
            " [-1 -1 -1 -1 -1 -1  1  1  1  1]]\n",
            "Step 1: Placed 3x3 drone at (12, 9), reward: 23.60\n",
            "[[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1  1  1  1  1  0 -1 -1 -1]\n",
            " [-1 -1  1  1  1  1  0  1  1  0]\n",
            " [-1 -1  1  1  1  1  1  0  1  1]\n",
            " [-1 -1  1  0  0  0  1  1  1  1]\n",
            " [-1 -1  1  1  1  1  1  1  1  1]\n",
            " [-1 -1 -1 -1 -1 -1  1  1  1  1]]\n",
            "Step 2: Placed 5x5 drone at (2, 1), reward: 14.90\n",
            "[[ 1  1  0 -1 -1 -1 -1 -1 -1 -1]\n",
            " [ 0  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [ 1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [ 1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1  1  1  1  1  0 -1 -1 -1]\n",
            " [-1 -1  1  1  1  1  0  1  1  0]\n",
            " [-1 -1  1  1  1  1  1  0  1  1]\n",
            " [-1 -1  1  0  0  0  1  1  1  1]\n",
            " [-1 -1  1  1  1  1  1  1  1  1]\n",
            " [-1 -1 -1 -1 -1 -1  1  1  1  1]]\n",
            "Step 3: Placed 3x3 drone at (3, 5), reward: 18.90\n",
            "[[ 1  1  0 -1 -1  1  1  0  0  1]\n",
            " [ 0  1  1 -1 -1  1  1  1  1  1]\n",
            " [ 1  1  1 -1 -1  1  1  1  1  1]\n",
            " [ 1  1  1 -1 -1  1  1  0  1  1]\n",
            " [-1 -1  1  1  1  1  0 -1 -1 -1]\n",
            " [-1 -1  1  1  1  1  0  1  1  0]\n",
            " [-1 -1  1  1  1  1  1  0  1  1]\n",
            " [-1 -1  1  0  0  0  1  1  1  1]\n",
            " [-1 -1  1  1  1  1  1  1  1  1]\n",
            " [-1 -1 -1 -1 -1 -1  1  1  1  1]]\n",
            "Step 4: Placed 3x3 drone at (7, 6), reward: 2.10\n",
            "[[ 1  1  0 -1 -1  1  1  0  0  1]\n",
            " [ 0  1  1 -1 -1  1  1  1  1  1]\n",
            " [ 1  1  1 -1 -1  1  1  1  1  1]\n",
            " [ 1  1  1 -1 -1  1  1  0  1  1]\n",
            " [-1 -1  1  1  1  1  0  1  0  1]\n",
            " [-1 -1  1  1  1  1  0  1  1  0]\n",
            " [-1 -1  1  1  1  1  1  0  1  1]\n",
            " [-1 -1  1  0  0  0  1  1  1  1]\n",
            " [-1 -1  1  1  1  1  1  1  1  1]\n",
            " [-1 -1 -1 -1 -1 -1  1  1  1  1]]\n",
            "Step 5: Placed 3x3 drone at (16, 1), reward: 11.90\n",
            "[[ 1  1  0 -1 -1  1  1  0  0  1]\n",
            " [ 0  1  1 -1 -1  1  1  1  1  1]\n",
            " [ 1  1  1 -1 -1  1  1  1  1  1]\n",
            " [ 1  1  1 -1 -1  1  1  0  1  1]\n",
            " [-1 -1  1  1  1  1  0  1  0  1]\n",
            " [-1 -1  1  1  1  1  0  1  1  0]\n",
            " [ 0  1  1  1  1  1  1  0  1  1]\n",
            " [ 1  0  1  0  0  0  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  0 -1 -1 -1  1  1  1  1]]\n",
            "Step 6: Placed 5x5 drone at (9, 4), reward: -1.20\n",
            "[[ 1  1  0 -1 -1  1  1  0  0  1]\n",
            " [ 0  1  1 -1 -1  1  1  1  1  1]\n",
            " [ 1  1  1 -1 -1  1  1  1  1  1]\n",
            " [ 1  1  1 -1 -1  1  1  0  1  1]\n",
            " [-1 -1  1  1  1  1  0  1  0  1]\n",
            " [-1 -1  1  1  1  1  0  1  1  0]\n",
            " [ 0  1  1  1  1  1  1  0  1  1]\n",
            " [ 1  0  1  0  0  0  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  0 -1 -1 -1  1  1  1  1]]\n",
            "Step 7: Placed 3x3 drone at (5, 3), reward: 2.60\n",
            "[[ 1  1  0 -1  1  1  1  0  0  1]\n",
            " [ 0  1  1 -1  1  1  1  1  1  1]\n",
            " [ 1  1  1 -1  1  1  1  1  1  1]\n",
            " [ 1  1  1 -1  1  1  1  0  1  1]\n",
            " [-1 -1  1  1  1  1  0  1  0  1]\n",
            " [-1 -1  1  1  1  1  0  1  1  0]\n",
            " [ 0  1  1  1  1  1  1  0  1  1]\n",
            " [ 1  0  1  0  0  0  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  0 -1 -1 -1  1  1  1  1]]\n",
            "Step 8: Placed 5x5 drone at (18, 2), reward: -0.90\n",
            "[[ 1  1  0 -1  1  1  1  0  0  1]\n",
            " [ 0  1  1 -1  1  1  1  1  1  1]\n",
            " [ 1  1  1 -1  1  1  1  1  1  1]\n",
            " [ 1  1  1 -1  1  1  1  0  1  1]\n",
            " [-1 -1  1  1  1  1  0  1  0  1]\n",
            " [-1 -1  1  1  1  1  0  1  1  0]\n",
            " [ 0  1  1  1  1  1  1  0  1  1]\n",
            " [ 1  0  1  0  0  0  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  0 -1 -1 -1  1  1  1  1]]\n",
            "Step 9: Placed 5x5 drone at (4, 2), reward: 1.10\n",
            "[[ 1  1  0 -1  1  1  1  0  0  1]\n",
            " [ 0  1  1 -1  1  1  1  1  1  1]\n",
            " [ 1  1  1 -1  1  1  1  1  1  1]\n",
            " [ 1  1  1 -1  1  1  1  0  1  1]\n",
            " [-1 -1  1  1  1  1  0  1  0  1]\n",
            " [-1 -1  1  1  1  1  0  1  1  0]\n",
            " [ 0  1  1  1  1  1  1  0  1  1]\n",
            " [ 1  0  1  0  0  0  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  0 -1 -1 -1  1  1  1  1]]\n",
            "Step 10: Placed 3x3 drone at (17, 1), reward: 1.90\n",
            "[[ 1  1  0 -1  1  1  1  0  0  1]\n",
            " [ 0  1  1 -1  1  1  1  1  1  1]\n",
            " [ 1  1  1 -1  1  1  1  1  1  1]\n",
            " [ 1  1  1 -1  1  1  1  0  1  1]\n",
            " [-1 -1  1  1  1  1  0  1  0  1]\n",
            " [-1 -1  1  1  1  1  0  1  1  0]\n",
            " [ 0  1  1  1  1  1  1  0  1  1]\n",
            " [ 1  0  1  0  0  0  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  0  1  0  1  1  1  1  1]]\n",
            "Step 11: Placed 5x5 drone at (4, 2), reward: 1.10\n",
            "[[ 1  1  0 -1  1  1  1  0  0  1]\n",
            " [ 0  1  1 -1  1  1  1  1  1  1]\n",
            " [ 1  1  1 -1  1  1  1  1  1  1]\n",
            " [ 1  1  1 -1  1  1  1  0  1  1]\n",
            " [-1 -1  1  1  1  1  0  1  0  1]\n",
            " [-1 -1  1  1  1  1  0  1  1  0]\n",
            " [ 0  1  1  1  1  1  1  0  1  1]\n",
            " [ 1  0  1  0  0  0  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  0  1  0  1  1  1  1  1]]\n",
            "Step 12: Placed 5x5 drone at (9, 2), reward: -1.20\n",
            "[[ 1  1  0 -1  1  1  1  0  0  1]\n",
            " [ 0  1  1 -1  1  1  1  1  1  1]\n",
            " [ 1  1  1 -1  1  1  1  1  1  1]\n",
            " [ 1  1  1 -1  1  1  1  0  1  1]\n",
            " [-1 -1  1  1  1  1  0  1  0  1]\n",
            " [-1 -1  1  1  1  1  0  1  1  0]\n",
            " [ 0  1  1  1  1  1  1  0  1  1]\n",
            " [ 1  0  1  0  0  0  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  0  1  0  1  1  1  1  1]]\n",
            "Step 13: Placed 5x5 drone at (4, 1), reward: 2.90\n",
            "[[ 1  1  0 -1  1  1  1  0  0  1]\n",
            " [ 0  1  1 -1  1  1  1  1  1  1]\n",
            " [ 1  1  1 -1  1  1  1  1  1  1]\n",
            " [ 1  1  1 -1  1  1  1  0  1  1]\n",
            " [ 0  1  1  1  1  1  0  1  0  1]\n",
            " [-1 -1  1  1  1  1  0  1  1  0]\n",
            " [ 0  1  1  1  1  1  1  0  1  1]\n",
            " [ 1  0  1  0  0  0  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  0  1  0  1  1  1  1  1]]\n",
            "Step 14: Placed 3x3 drone at (2, 2), reward: 1.10\n",
            "[[ 1  1  0 -1  1  1  1  0  0  1]\n",
            " [ 0  1  1 -1  1  1  1  1  1  1]\n",
            " [ 1  1  1 -1  1  1  1  1  1  1]\n",
            " [ 1  1  1 -1  1  1  1  0  1  1]\n",
            " [ 0  1  1  1  1  1  0  1  0  1]\n",
            " [-1 -1  1  1  1  1  0  1  1  0]\n",
            " [ 0  1  1  1  1  1  1  0  1  1]\n",
            " [ 1  0  1  0  0  0  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  0  1  0  1  1  1  1  1]]\n",
            "Step 15: Placed 3x3 drone at (2, 3), reward: 6.90\n",
            "[[ 1  1  0  0  1  1  1  0  0  1]\n",
            " [ 0  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  0  1  1]\n",
            " [ 0  1  1  1  1  1  0  1  0  1]\n",
            " [-1 -1  1  1  1  1  0  1  1  0]\n",
            " [ 0  1  1  1  1  1  1  0  1  1]\n",
            " [ 1  0  1  0  0  0  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  0  1  0  1  1  1  1  1]]\n",
            "Step 16: Placed 5x5 drone at (4, 0), reward: 1.10\n",
            "[[ 1  1  0  0  1  1  1  0  0  1]\n",
            " [ 0  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  0  1  1]\n",
            " [ 0  1  1  1  1  1  0  1  0  1]\n",
            " [-1 -1  1  1  1  1  0  1  1  0]\n",
            " [ 0  1  1  1  1  1  1  0  1  1]\n",
            " [ 1  0  1  0  0  0  1  1  1  1]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  0  1  0  1  1  1  1  1]]\n",
            "Step 17: Placed 5x5 drone at (6, 1), reward: 16.00\n",
            "[[1 1 0 0 1 1 1 0 0 1]\n",
            " [0 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 0 1 1]\n",
            " [0 1 1 1 1 1 0 1 0 1]\n",
            " [1 1 1 1 1 1 0 1 1 0]\n",
            " [0 1 1 1 1 1 1 0 1 1]\n",
            " [1 0 1 0 0 0 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 0 1 0 1 1 1 1 1]]\n",
            "Mission Complete: All cells explored!\n"
          ]
        }
      ],
      "source": [
        "def run_trained_model_advanced():\n",
        "    model = PPO.load(\"ppo_bigmap_advanced_model_2\")\n",
        "    # same environment as in training\n",
        "    env = AdvancedDroneEnv(grid_size=10, max_steps=60, init_battery=80)\n",
        "    obs, _ = env.reset()\n",
        "\n",
        "    for step in range(env.max_steps):\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, reward, terminated, truncated, _ = env.step(action)\n",
        "        x = action // 20\n",
        "        y = (action % 20) // 2\n",
        "        drone_type = \"3x3\" if action % 2 == 0 else \"5x5\"\n",
        "        print(f\"Step {step}: Placed {drone_type} drone at ({x}, {y}), reward: {reward:.2f}\")\n",
        "        env.render()\n",
        "        if terminated or truncated:\n",
        "            print(\"Mission Complete: All cells explored!\")\n",
        "            break\n",
        "        if truncated:\n",
        "            print(\"Max steps reached.\")\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_trained_model_advanced()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5Klr58UG83n"
      },
      "source": [
        "# Env 3: Env 2 + Must land in safe zone to get final reward, Dynamic grid, Parallel agents. Resultâ‰ˆ9-59steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxYtrnZjdbG8",
        "outputId": "1f3fc657-7fe7-4360-b8b8-6e67993f4808"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "singleâ€‘agent random reward: 46.05\n"
          ]
        }
      ],
      "source": [
        "# dynamic_marl_env.py\n",
        "import numpy as np\n",
        "import random\n",
        "from gymnasium import spaces\n",
        "\n",
        "# 1. Single-agent extension: dynamic obstacles + landing zones\n",
        "class DynamicLandingEnv(AdvancedDroneEnv):\n",
        "    def __init__(\n",
        "        self,\n",
        "        grid_size=10,\n",
        "        max_steps=60,\n",
        "        init_battery=80,\n",
        "        dynamic_flip_prob=0.02,      # Probability for cell to flip state\n",
        "        landing_buffer=1\n",
        "    ):\n",
        "        self.dynamic_flip_prob = dynamic_flip_prob\n",
        "        self.landing_buffer = landing_buffer\n",
        "        super().__init__(grid_size=grid_size, max_steps=max_steps, init_battery=init_battery)\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        obs, info = super().reset(seed=seed)\n",
        "        self.landable_set = self._compute_landable()\n",
        "        return obs, info\n",
        "\n",
        "    def step(self, action):\n",
        "        # First update dynamic obstacles\n",
        "        self._update_dynamic()\n",
        "\n",
        "        obs, r, terminated, truncated, info = super().step(action)\n",
        "\n",
        "        # mission complete or timeout\n",
        "        if terminated or truncated:\n",
        "            if hasattr(self, \"last_xy\"):\n",
        "                landed_ok = self.last_xy in self.landable_set\n",
        "                # +5 / -5 landing bonus\n",
        "                r += 5.0 if landed_ok else -5.0\n",
        "                info[\"landed_ok\"] = landed_ok\n",
        "        return obs, r, terminated, truncated, info\n",
        "\n",
        "    # record the final coordinates\n",
        "    def step(self, action):\n",
        "        role_bit = action % 2\n",
        "        pure_action = action // 2\n",
        "        a_per_row = self.grid_size * 2\n",
        "        x = pure_action // a_per_row\n",
        "        y = (pure_action % a_per_row) // 2\n",
        "        self.last_xy = (x, y)\n",
        "\n",
        "        # Continue with parent logic (after dynamic obstacle update)\n",
        "        return super().step(action)\n",
        "\n",
        "    # Dynamic obstacle update\n",
        "    def _update_dynamic(self):\n",
        "        flip_mask = np.random.rand(*self.actual_env.shape) < self.dynamic_flip_prob\n",
        "        # Flip between SAFE and OBSTACLE\n",
        "        self.actual_env[flip_mask & (self.actual_env == 1)] = 0\n",
        "        self.actual_env[flip_mask & (self.actual_env == 0)] = 1\n",
        "\n",
        "    # Compute landing zones\n",
        "    def _compute_landable(self):\n",
        "        landable = set()\n",
        "        for x in range(self.grid_size):\n",
        "            for y in range(self.grid_size):\n",
        "                if self.actual_env[x, y] != 1:      # Must be SAFE\n",
        "                    continue\n",
        "                ok = True\n",
        "                # All surrounding cells within the buffer must be SAFE\n",
        "                for dx in range(-self.landing_buffer, self.landing_buffer + 1):\n",
        "                    for dy in range(-self.landing_buffer, self.landing_buffer + 1):\n",
        "                        gx, gy = x + dx, y + dy\n",
        "                        if 0 <= gx < self.grid_size and 0 <= gy < self.grid_size:\n",
        "                            if self.actual_env[gx, gy] == 0:\n",
        "                                ok = False; break\n",
        "                    if not ok: break\n",
        "                if ok:\n",
        "                    landable.add((x, y))\n",
        "        # Guarantee at least (0,0) is a valid landing zone\n",
        "        landable.add((0, 0))\n",
        "        return landable\n",
        "\n",
        "\n",
        "# Multi-agent PettingZoo environment (Explorer vs Relay)\n",
        "from pettingzoo.utils.env import ParallelEnv\n",
        "from pettingzoo.utils import wrappers\n",
        "\n",
        "EXPLORER = 0\n",
        "RELAY    = 1\n",
        "\n",
        "class MultiDroneEnv(ParallelEnv):\n",
        "    \"\"\"\n",
        "    â€¢ n_explorers perform scanning\n",
        "    â€¢ n_relays act as static relays (do not scan or move)\n",
        "      â†’ You can extend this to allow relays to move\n",
        "    Action structure is identical to single-agent, but separated by agent\n",
        "    Observation = shared global grid\n",
        "    \"\"\"\n",
        "    metadata = {\"name\": \"multi_drone_v0\"}\n",
        "    render_mode = None\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_explorers=2,\n",
        "        n_relays=1,\n",
        "        grid_size=10,\n",
        "        max_steps=60,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.grid_size = grid_size\n",
        "        self.max_steps = max_steps\n",
        "        self.n_explorers = n_explorers\n",
        "        self.n_relays = n_relays\n",
        "\n",
        "        # Underlying single-agent environment\n",
        "        self.base_env = DynamicLandingEnv(grid_size=grid_size,max_steps=max_steps)\n",
        "\n",
        "        # agent ids\n",
        "        self.agent_names = (\n",
        "            [f\"explorer_{i}\" for i in range(n_explorers)] +\n",
        "            [f\"relay_{i}\"     for i in range(n_relays)]\n",
        "        )\n",
        "        self.possible_agents = list(self.agent_names)\n",
        "\n",
        "        self.action_spaces = {agent: self.base_env.action_space\n",
        "                              for agent in self.agent_names}\n",
        "        self.observation_spaces = {agent: self.base_env.observation_space\n",
        "                                   for agent in self.agent_names}\n",
        "\n",
        "    # PettingZoo API\n",
        "    def reset(self, seed=None, options=None):\n",
        "        obs, _ = self.base_env.reset(seed=seed)\n",
        "        self.steps = 0\n",
        "        self.agents = list(self.agent_names)\n",
        "        info = {a: {} for a in self.agent_names}\n",
        "        return {a: obs.copy() for a in self.agent_names}, info\n",
        "\n",
        "\n",
        "\n",
        "    def step(self, actions):\n",
        "        \"\"\"\n",
        "        actions: {agent_name: action_int}\n",
        "        We only execute one explorerâ€™s action for simplicity;\n",
        "        You can change this to queue all actions or use turn-based logic.\n",
        "        \"\"\"\n",
        "        self.steps += 1\n",
        "        exec_agent = f\"explorer_{self.steps % self.n_explorers}\"\n",
        "        action_to_exec = actions.get(exec_agent,\n",
        "                                     self.base_env.action_space.sample())\n",
        "        obs, r, term, trunc, info = self.base_env.step(int(action_to_exec))\n",
        "\n",
        "        # Same reward is shared by all agents\n",
        "        rewards = {a: r for a in self.agent_names}\n",
        "        terminations = {a: term for a in self.agent_names}\n",
        "        truncations  = {a: trunc for a in self.agent_names}\n",
        "        infos        = {a: info for a in self.agent_names}\n",
        "        observations = {a: obs.copy() for a in self.agent_names}\n",
        "\n",
        "        # Global termination\n",
        "        if term or trunc or self.steps >= self.max_steps:\n",
        "            terminations = {a: True for a in self.agent_names}\n",
        "            truncations  = {a: trunc for a in self.agent_names}\n",
        "            self.agents = []\n",
        "\n",
        "        return observations, rewards, terminations, truncations, infos\n",
        "\n",
        "    def render(self):\n",
        "        self.base_env.render()\n",
        "\n",
        "    def close(self):\n",
        "        pass\n",
        "\n",
        "# Optionally wrap with supersuit utilities\n",
        "def ss_env(**kwargs):\n",
        "    raw_env = MultiDroneEnv(**kwargs)\n",
        "    wrapped = ss.pad_observations_v0(ss.pad_action_space_v0(raw_env))\n",
        "    return wrapped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u5DsgalUdzhN",
        "outputId": "c946e103-7f02-46df-cf6d-a088c4f89179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Phase 1: Small grid MARL training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pettingzoo/utils/env.py:370: UserWarning: Your environment should override the action_space function. Attempting to use the action_spaces dict attribute.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/pettingzoo/utils/env.py:358: UserWarning: Your environment should override the observation_space function. Attempting to use the observation_spaces dict attribute.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 2684  |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 9     |\n",
            "|    total_timesteps | 24576 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 1379        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 35          |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021091426 |\n",
            "|    clip_fraction        | 0.186       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.96       |\n",
            "|    explained_variance   | 0.0181      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.78        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0301     |\n",
            "|    value_loss           | 65.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 1187        |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 62          |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018075408 |\n",
            "|    clip_fraction        | 0.198       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.93       |\n",
            "|    explained_variance   | 0.826       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.15        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0377     |\n",
            "|    value_loss           | 12.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 1109        |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 88          |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018382296 |\n",
            "|    clip_fraction        | 0.217       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.91       |\n",
            "|    explained_variance   | 0.89        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.88        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0402     |\n",
            "|    value_loss           | 9.34        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 1068        |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 115         |\n",
            "|    total_timesteps      | 122880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019118631 |\n",
            "|    clip_fraction        | 0.239       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.87       |\n",
            "|    explained_variance   | 0.926       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.45        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0435     |\n",
            "|    value_loss           | 7.03        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 1041       |\n",
            "|    iterations           | 6          |\n",
            "|    time_elapsed         | 141        |\n",
            "|    total_timesteps      | 147456     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01862774 |\n",
            "|    clip_fraction        | 0.23       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.84      |\n",
            "|    explained_variance   | 0.936      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.5        |\n",
            "|    n_updates            | 50         |\n",
            "|    policy_gradient_loss | -0.0404    |\n",
            "|    value_loss           | 6.91       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 1022       |\n",
            "|    iterations           | 7          |\n",
            "|    time_elapsed         | 168        |\n",
            "|    total_timesteps      | 172032     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01895892 |\n",
            "|    clip_fraction        | 0.235      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.81      |\n",
            "|    explained_variance   | 0.937      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.2        |\n",
            "|    n_updates            | 60         |\n",
            "|    policy_gradient_loss | -0.0399    |\n",
            "|    value_loss           | 6.99       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 1009        |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 194         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018993596 |\n",
            "|    clip_fraction        | 0.243       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.77       |\n",
            "|    explained_variance   | 0.942       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.17        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0407     |\n",
            "|    value_loss           | 6.5         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 997         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 221         |\n",
            "|    total_timesteps      | 221184      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019059528 |\n",
            "|    clip_fraction        | 0.248       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.73       |\n",
            "|    explained_variance   | 0.953       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.5         |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0405     |\n",
            "|    value_loss           | 5.49        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 985         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 249         |\n",
            "|    total_timesteps      | 245760      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019510055 |\n",
            "|    clip_fraction        | 0.25        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.68       |\n",
            "|    explained_variance   | 0.948       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.17        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0405     |\n",
            "|    value_loss           | 6.19        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 979         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 275         |\n",
            "|    total_timesteps      | 270336      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019178135 |\n",
            "|    clip_fraction        | 0.252       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.63       |\n",
            "|    explained_variance   | 0.951       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.74        |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0408     |\n",
            "|    value_loss           | 5.69        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 975         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 302         |\n",
            "|    total_timesteps      | 294912      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018900247 |\n",
            "|    clip_fraction        | 0.252       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.58       |\n",
            "|    explained_variance   | 0.948       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.35        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0398     |\n",
            "|    value_loss           | 6.15        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 971         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 328         |\n",
            "|    total_timesteps      | 319488      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018983778 |\n",
            "|    clip_fraction        | 0.256       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.52       |\n",
            "|    explained_variance   | 0.946       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.43        |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0396     |\n",
            "|    value_loss           | 6.73        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 969         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 355         |\n",
            "|    total_timesteps      | 344064      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019386152 |\n",
            "|    clip_fraction        | 0.246       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.46       |\n",
            "|    explained_variance   | 0.935       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.61        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0387     |\n",
            "|    value_loss           | 7.66        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 966         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 381         |\n",
            "|    total_timesteps      | 368640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018733473 |\n",
            "|    clip_fraction        | 0.24        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.4        |\n",
            "|    explained_variance   | 0.934       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.53        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0378     |\n",
            "|    value_loss           | 7.57        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 964         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 407         |\n",
            "|    total_timesteps      | 393216      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018572612 |\n",
            "|    clip_fraction        | 0.233       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.34       |\n",
            "|    explained_variance   | 0.917       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.4         |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0356     |\n",
            "|    value_loss           | 9.52        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 962         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 434         |\n",
            "|    total_timesteps      | 417792      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018999951 |\n",
            "|    clip_fraction        | 0.225       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.29       |\n",
            "|    explained_variance   | 0.904       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.9         |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0361     |\n",
            "|    value_loss           | 10.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 958         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 461         |\n",
            "|    total_timesteps      | 442368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018790582 |\n",
            "|    clip_fraction        | 0.225       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.24       |\n",
            "|    explained_variance   | 0.893       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.48        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0342     |\n",
            "|    value_loss           | 11.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 956         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 487         |\n",
            "|    total_timesteps      | 466944      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018316066 |\n",
            "|    clip_fraction        | 0.224       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.19       |\n",
            "|    explained_variance   | 0.887       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.55        |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.0343     |\n",
            "|    value_loss           | 12.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 954         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 514         |\n",
            "|    total_timesteps      | 491520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018093048 |\n",
            "|    clip_fraction        | 0.218       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.15       |\n",
            "|    explained_variance   | 0.873       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.42        |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0323     |\n",
            "|    value_loss           | 13.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 953         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 541         |\n",
            "|    total_timesteps      | 516096      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018940417 |\n",
            "|    clip_fraction        | 0.226       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.11       |\n",
            "|    explained_variance   | 0.859       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.67        |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.0333     |\n",
            "|    value_loss           | 15.7        |\n",
            "-----------------------------------------\n",
            "âœ… Stage 1 model & encoder saved.\n",
            "\n",
            "ðŸ“— Phase 2: Large grid MARL fine-tuning\n",
            "Using cuda device\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 3411  |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 14    |\n",
            "|    total_timesteps | 49152 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 1453        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 67          |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022263905 |\n",
            "|    clip_fraction        | 0.217       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.97       |\n",
            "|    explained_variance   | 0.00389     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.8         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0461     |\n",
            "|    value_loss           | 98.1        |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1179      |\n",
            "|    iterations           | 3         |\n",
            "|    time_elapsed         | 124       |\n",
            "|    total_timesteps      | 147456    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0205419 |\n",
            "|    clip_fraction        | 0.213     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -5.95     |\n",
            "|    explained_variance   | 0.835     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.59      |\n",
            "|    n_updates            | 20        |\n",
            "|    policy_gradient_loss | -0.0517   |\n",
            "|    value_loss           | 27.2      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 1115        |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 176         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023018816 |\n",
            "|    clip_fraction        | 0.243       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.93       |\n",
            "|    explained_variance   | 0.886       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.19        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0577     |\n",
            "|    value_loss           | 21.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 1060        |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 231         |\n",
            "|    total_timesteps      | 245760      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024309913 |\n",
            "|    clip_fraction        | 0.254       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.9        |\n",
            "|    explained_variance   | 0.9         |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.92        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0585     |\n",
            "|    value_loss           | 20.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 1026        |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 287         |\n",
            "|    total_timesteps      | 294912      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025738882 |\n",
            "|    clip_fraction        | 0.271       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.88       |\n",
            "|    explained_variance   | 0.903       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.95        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0597     |\n",
            "|    value_loss           | 18          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 982         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 350         |\n",
            "|    total_timesteps      | 344064      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026872212 |\n",
            "|    clip_fraction        | 0.283       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.85       |\n",
            "|    explained_variance   | 0.921       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.94        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0611     |\n",
            "|    value_loss           | 17.9        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 958        |\n",
            "|    iterations           | 8          |\n",
            "|    time_elapsed         | 410        |\n",
            "|    total_timesteps      | 393216     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02805247 |\n",
            "|    clip_fraction        | 0.291      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -5.82      |\n",
            "|    explained_variance   | 0.922      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 7.75       |\n",
            "|    n_updates            | 70         |\n",
            "|    policy_gradient_loss | -0.0613    |\n",
            "|    value_loss           | 16.7       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 946         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 467         |\n",
            "|    total_timesteps      | 442368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.029047742 |\n",
            "|    clip_fraction        | 0.298       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.79       |\n",
            "|    explained_variance   | 0.929       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.89        |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0622     |\n",
            "|    value_loss           | 15.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 943         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 521         |\n",
            "|    total_timesteps      | 491520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.029162183 |\n",
            "|    clip_fraction        | 0.296       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.76       |\n",
            "|    explained_variance   | 0.932       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.16        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0614     |\n",
            "|    value_loss           | 16.3        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 938        |\n",
            "|    iterations           | 11         |\n",
            "|    time_elapsed         | 576        |\n",
            "|    total_timesteps      | 540672     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03031002 |\n",
            "|    clip_fraction        | 0.311      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -5.73      |\n",
            "|    explained_variance   | 0.931      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.29       |\n",
            "|    n_updates            | 100        |\n",
            "|    policy_gradient_loss | -0.0621    |\n",
            "|    value_loss           | 15.7       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 935         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 630         |\n",
            "|    total_timesteps      | 589824      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.031043416 |\n",
            "|    clip_fraction        | 0.319       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.69       |\n",
            "|    explained_variance   | 0.937       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.84        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0622     |\n",
            "|    value_loss           | 15.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 932         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 685         |\n",
            "|    total_timesteps      | 638976      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.031341355 |\n",
            "|    clip_fraction        | 0.32        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.66       |\n",
            "|    explained_variance   | 0.945       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.96        |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0616     |\n",
            "|    value_loss           | 14.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 930         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 739         |\n",
            "|    total_timesteps      | 688128      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.031961884 |\n",
            "|    clip_fraction        | 0.329       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.62       |\n",
            "|    explained_variance   | 0.946       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.71        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0624     |\n",
            "|    value_loss           | 15          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 930         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 792         |\n",
            "|    total_timesteps      | 737280      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.031801067 |\n",
            "|    clip_fraction        | 0.325       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.59       |\n",
            "|    explained_variance   | 0.946       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.2         |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0611     |\n",
            "|    value_loss           | 15.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 923         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 851         |\n",
            "|    total_timesteps      | 786432      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.032997895 |\n",
            "|    clip_fraction        | 0.335       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.56       |\n",
            "|    explained_variance   | 0.947       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.02        |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0627     |\n",
            "|    value_loss           | 14.4        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 921        |\n",
            "|    iterations           | 17         |\n",
            "|    time_elapsed         | 907        |\n",
            "|    total_timesteps      | 835584     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03312896 |\n",
            "|    clip_fraction        | 0.335      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -5.53      |\n",
            "|    explained_variance   | 0.951      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.33       |\n",
            "|    n_updates            | 160        |\n",
            "|    policy_gradient_loss | -0.0622    |\n",
            "|    value_loss           | 14.7       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 916         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 964         |\n",
            "|    total_timesteps      | 884736      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.033982854 |\n",
            "|    clip_fraction        | 0.339       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.49       |\n",
            "|    explained_variance   | 0.95        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.58        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0617     |\n",
            "|    value_loss           | 14.7        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 908        |\n",
            "|    iterations           | 19         |\n",
            "|    time_elapsed         | 1027       |\n",
            "|    total_timesteps      | 933888     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03461272 |\n",
            "|    clip_fraction        | 0.345      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -5.44      |\n",
            "|    explained_variance   | 0.952      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 5.13       |\n",
            "|    n_updates            | 180        |\n",
            "|    policy_gradient_loss | -0.0617    |\n",
            "|    value_loss           | 14.2       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 905         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 1085        |\n",
            "|    total_timesteps      | 983040      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.035091218 |\n",
            "|    clip_fraction        | 0.348       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.4        |\n",
            "|    explained_variance   | 0.956       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.9         |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0624     |\n",
            "|    value_loss           | 14          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 909         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 1135        |\n",
            "|    total_timesteps      | 1032192     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.034686904 |\n",
            "|    clip_fraction        | 0.344       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.37       |\n",
            "|    explained_variance   | 0.957       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.29        |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.0608     |\n",
            "|    value_loss           | 14.1        |\n",
            "-----------------------------------------\n",
            "ðŸŽ¯ Stage 2 MARL training complete.\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3 import PPO\n",
        "import supersuit as ss\n",
        "import torch\n",
        "\n",
        "# Phase 1: Small Grid\n",
        "def train_stage1_small_marl():\n",
        "    print(\" Phase 1: Small grid MARL training\")\n",
        "\n",
        "    def ss_env_small():\n",
        "        raw_env = MultiDroneEnv(grid_size=6, max_steps=30)\n",
        "        return ss.pad_observations_v0(ss.pad_action_space_v0(raw_env))\n",
        "\n",
        "    petting_env = ss_env_small()\n",
        "    vec_env = ss.pettingzoo_env_to_vec_env_v1(petting_env)\n",
        "    vec_env = ss.concat_vec_envs_v1(vec_env, num_vec_envs=4, num_cpus=2, base_class=\"stable_baselines3\")\n",
        "\n",
        "    model = PPO(\"MlpPolicy\", vec_env,\n",
        "                device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "                verbose=1,\n",
        "                policy_kwargs=dict(net_arch=[dict(pi=[64, 64], vf=[64, 64])]))\n",
        "\n",
        "    model.learn(total_timesteps=500_000)\n",
        "    model.save(\"ppo_marl_stage1_small\")\n",
        "\n",
        "    encoder_state = {\n",
        "        k: v for k, v in model.policy.mlp_extractor.state_dict().items()\n",
        "        if not k.startswith(\"policy_net.0\") and not k.startswith(\"value_net.0\")\n",
        "    }\n",
        "    torch.save(encoder_state, \"encoder_marl_stage1.pt\")\n",
        "    print(\" Stage 1 model & encoder saved.\")\n",
        "\n",
        "\n",
        "# Phase 2: Large Grid\n",
        "def train_stage2_big_marl():\n",
        "    print(\"\\n Phase 2: Large grid MARL fine-tuning\")\n",
        "\n",
        "    def ss_env_big():\n",
        "        raw_env = MultiDroneEnv(grid_size=10, max_steps=60)\n",
        "        return ss.pad_observations_v0(ss.pad_action_space_v0(raw_env))\n",
        "\n",
        "    petting_env = ss_env_big()\n",
        "    vec_env = ss.pettingzoo_env_to_vec_env_v1(petting_env)\n",
        "    vec_env = ss.concat_vec_envs_v1(vec_env, num_vec_envs=8, num_cpus=4, base_class=\"stable_baselines3\")\n",
        "\n",
        "    model = PPO(\"MlpPolicy\", vec_env,\n",
        "                device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "                verbose=1,\n",
        "                policy_kwargs=dict(net_arch=[dict(pi=[64, 64], vf=[64, 64])]))\n",
        "\n",
        "    encoder_state = torch.load(\"encoder_marl_stage1.pt\")\n",
        "    model.policy.mlp_extractor.load_state_dict(encoder_state, strict=False)\n",
        "\n",
        "    model.learn(total_timesteps=1000_000)\n",
        "    model.save(\"ppo_marl_drones_gpu_3\")\n",
        "    print(\"Stage 2 MARL training complete.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_stage1_small_marl()\n",
        "    train_stage2_big_marl()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynhMUmLji_Rk",
        "outputId": "e09c2d1d-bc3f-41a2-8d0f-26cd1900b66b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Step 0\n",
            "explorer_0: 5x5 drone at (6, 0) â†’ reward: 7.10\n",
            "explorer_1: 5x5 drone at (6, 0) â†’ reward: 7.10\n",
            "relay_0: 5x5 drone at (6, 0) â†’ reward: 7.10\n",
            "[[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [ 0  1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [ 1  0 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [ 1  1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
            "\n",
            " Step 1\n",
            "explorer_0: 3x3 drone at (13, 1) â†’ reward: 31.60\n",
            "explorer_1: 3x3 drone at (13, 1) â†’ reward: 31.60\n",
            "relay_0: 3x3 drone at (13, 1) â†’ reward: 31.60\n",
            "[[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [ 0  1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [ 1  0 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [ 1  1 -1  1  0  0  1  0 -1 -1]\n",
            " [-1 -1 -1  1  1  0  1  0 -1 -1]\n",
            " [-1 -1 -1  1  0  1  1  1 -1 -1]\n",
            " [-1 -1 -1  1  1  1  1  1 -1 -1]\n",
            " [-1 -1 -1  1  1  1  1  1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
            "\n",
            " Step 2\n",
            "explorer_0: 3x3 drone at (5, 1) â†’ reward: 20.60\n",
            "explorer_1: 3x3 drone at (5, 1) â†’ reward: 20.60\n",
            "relay_0: 3x3 drone at (5, 1) â†’ reward: 20.60\n",
            "[[-1 -1 -1  0  1  1  1  1 -1 -1]\n",
            " [-1 -1 -1  1  1  1  1  1 -1 -1]\n",
            " [ 0  1 -1  1  0  1  1  0 -1 -1]\n",
            " [ 1  0 -1  0  1  1  1  1 -1 -1]\n",
            " [ 1  1 -1  1  0  0  1  0 -1 -1]\n",
            " [-1 -1 -1  1  1  0  1  0 -1 -1]\n",
            " [-1 -1 -1  1  0  1  1  1 -1 -1]\n",
            " [-1 -1 -1  1  1  1  1  1 -1 -1]\n",
            " [-1 -1 -1  1  1  1  1  1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
            "\n",
            " Step 3\n",
            "explorer_0: 5x5 drone at (2, 2) â†’ reward: 10.10\n",
            "explorer_1: 5x5 drone at (2, 2) â†’ reward: 10.10\n",
            "relay_0: 5x5 drone at (2, 2) â†’ reward: 10.10\n",
            "[[ 1  1  0  0  1  1  1  1 -1 -1]\n",
            " [ 1  1  1  1  1  1  1  1 -1 -1]\n",
            " [ 0  1  0  1  0  1  1  0 -1 -1]\n",
            " [ 1  0 -1  0  1  1  1  1 -1 -1]\n",
            " [ 1  1 -1  1  0  0  1  0 -1 -1]\n",
            " [-1 -1 -1  1  1  0  1  0 -1 -1]\n",
            " [-1 -1 -1  1  0  1  1  1 -1 -1]\n",
            " [-1 -1 -1  1  1  1  1  1 -1 -1]\n",
            " [-1 -1 -1  1  1  1  1  1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
            "\n",
            " Step 4\n",
            "explorer_0: 3x3 drone at (15, 9) â†’ reward: 9.90\n",
            "explorer_1: 3x3 drone at (15, 9) â†’ reward: 9.90\n",
            "relay_0: 3x3 drone at (15, 9) â†’ reward: 9.90\n",
            "[[ 1  1  0  0  1  1  1  1 -1 -1]\n",
            " [ 1  1  1  1  1  1  1  1 -1 -1]\n",
            " [ 0  1  0  1  0  1  1  0 -1 -1]\n",
            " [ 1  0 -1  0  1  1  1  1 -1 -1]\n",
            " [ 1  1 -1  1  0  0  1  0 -1 -1]\n",
            " [-1 -1 -1  1  1  0  1  0  1  1]\n",
            " [-1 -1 -1  1  0  1  1  1  0  0]\n",
            " [-1 -1 -1  1  1  1  1  1  1  0]\n",
            " [-1 -1 -1  1  1  1  1  1  1  1]\n",
            " [-1 -1 -1 -1 -1 -1 -1  1  0  1]]\n",
            "\n",
            " Step 5\n",
            "explorer_0: 3x3 drone at (12, 2) â†’ reward: 8.10\n",
            "explorer_1: 3x3 drone at (12, 2) â†’ reward: 8.10\n",
            "relay_0: 3x3 drone at (12, 2) â†’ reward: 8.10\n",
            "[[ 1  1  0  0  1  1  1  1 -1 -1]\n",
            " [ 1  1  1  1  1  1  1  1 -1 -1]\n",
            " [ 0  1  0  1  0  1  1  0 -1 -1]\n",
            " [ 1  0 -1  0  1  1  1  1 -1 -1]\n",
            " [ 1  1 -1  1  0  0  1  0 -1 -1]\n",
            " [ 1  1  1  1  1  0  1  0  1  1]\n",
            " [ 1  1  1  1  0  1  1  1  0  0]\n",
            " [ 1  1  1  1  1  1  1  1  1  0]\n",
            " [-1 -1 -1  1  1  1  1  1  1  1]\n",
            " [-1 -1 -1 -1 -1 -1 -1  1  0  1]]\n",
            "\n",
            " Step 6\n",
            "explorer_0: 5x5 drone at (5, 5) â†’ reward: 8.60\n",
            "explorer_1: 5x5 drone at (5, 5) â†’ reward: 8.60\n",
            "relay_0: 5x5 drone at (5, 5) â†’ reward: 8.60\n",
            "[[ 1  1  0  0  1  1  1  1  1  0]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 0  1  0  1  0  1  1  0  1  0]\n",
            " [ 1  0 -1  0  1  1  1  1  1  1]\n",
            " [ 1  1 -1  1  0  0  1  0  1  1]\n",
            " [ 1  1  1  1  1  0  1  0  1  1]\n",
            " [ 1  1  1  1  0  1  1  1  0  0]\n",
            " [ 1  1  1  1  1  1  1  1  1  0]\n",
            " [-1 -1 -1  1  1  1  1  1  1  1]\n",
            " [-1 -1 -1 -1 -1 -1 -1  1  0  1]]\n",
            "\n",
            " Step 7\n",
            "explorer_0: 3x3 drone at (14, 5) â†’ reward: 6.60\n",
            "explorer_1: 3x3 drone at (14, 5) â†’ reward: 6.60\n",
            "relay_0: 3x3 drone at (14, 5) â†’ reward: 6.60\n",
            "[[ 1  1  0  0  1  1  1  1  1  0]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 0  1  0  1  0  1  1  0  1  0]\n",
            " [ 1  0 -1  0  1  1  1  1  1  1]\n",
            " [ 1  1 -1  1  0  0  1  0  1  1]\n",
            " [ 1  1  1  1  1  0  1  0  1  1]\n",
            " [ 1  1  1  1  0  1  1  1  0  0]\n",
            " [ 1  1  1  1  1  1  1  1  1  0]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  1  1  1 -1 -1  1  0  1]]\n",
            "\n",
            " Step 8\n",
            "explorer_0: 5x5 drone at (4, 1) â†’ reward: 2.90\n",
            "explorer_1: 5x5 drone at (4, 1) â†’ reward: 2.90\n",
            "relay_0: 5x5 drone at (4, 1) â†’ reward: 2.90\n",
            "[[ 1  1  0  0  1  1  1  1  1  0]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 0  1  0  1  0  1  1  0  1  0]\n",
            " [ 1  0  1  0  1  1  1  1  1  1]\n",
            " [ 1  1  1  1  0  0  1  0  1  1]\n",
            " [ 1  1  1  1  1  0  1  0  1  1]\n",
            " [ 1  1  1  1  0  1  1  1  0  0]\n",
            " [ 1  1  1  1  1  1  1  1  1  0]\n",
            " [ 1  1  1  1  1  1  1  1  1  1]\n",
            " [ 1  1  1  1  1 -1 -1  1  0  1]]\n",
            "\n",
            " Step 9\n",
            "explorer_0: 5x5 drone at (17, 3) â†’ reward: 14.40\n",
            "explorer_1: 5x5 drone at (17, 3) â†’ reward: 14.40\n",
            "relay_0: 5x5 drone at (17, 3) â†’ reward: 14.40\n",
            "[[1 1 0 0 1 1 1 1 1 0]\n",
            " [1 1 1 1 1 1 1 1 1 1]\n",
            " [0 1 0 1 0 1 1 0 1 0]\n",
            " [1 0 1 0 1 1 1 1 1 1]\n",
            " [1 1 1 1 0 0 1 0 1 1]\n",
            " [1 1 1 1 1 0 1 0 1 1]\n",
            " [1 1 1 1 0 1 1 1 0 0]\n",
            " [1 1 1 1 1 1 1 1 1 0]\n",
            " [1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 0 1 0 1]]\n",
            "\n",
            " Episode finished!\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3 import PPO\n",
        "import supersuit as ss\n",
        "\n",
        "def run_marl_rollout():\n",
        "    model = PPO.load(\"ppo_marl_drones_gpu_3\")\n",
        "    env = ss_env(grid_size=10)  # already defined globally\n",
        "    obs, _ = env.reset()\n",
        "    step = 0\n",
        "\n",
        "    while env.agents:\n",
        "        print(f\"\\n Step {step}\")\n",
        "        actions = {}\n",
        "\n",
        "        for agent, observation in obs.items():\n",
        "            action, _ = model.predict(observation, deterministic=True)\n",
        "            actions[agent] = action\n",
        "\n",
        "        obs, rewards, terminations, truncations, infos = env.step(actions)\n",
        "\n",
        "        for agent in rewards:\n",
        "            x = actions[agent] // 20\n",
        "            y = (actions[agent] % 20) // 2\n",
        "            drone_type = \"3x3\" if actions[agent] % 2 == 0 else \"5x5\"\n",
        "            print(f\"{agent}: {drone_type} drone at ({x}, {y}) â†’ reward: {rewards[agent]:.2f}\")\n",
        "\n",
        "        env.render()\n",
        "        step += 1\n",
        "\n",
        "        if all(terminations.values()) or all(truncations.values()):\n",
        "            print(\"\\n Episode finished!\")\n",
        "            break\n",
        "\n",
        "run_marl_rollout()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
